#!/usr/bin/env python3
"""
Symbol Validation Monitoring Tool
Continuous monitoring and alerting for symbol format compliance and data consistency
"""

import mysql.connector
import json
import os
import time
from datetime import datetime, timedelta
from collections import defaultdict
import smtplib
from email.mime.text import MimeText
from email.mime.multipart import MimeMultipart

# Add shared directory to path
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), 'shared'))
from table_config import (
    PRIMARY_COLLECTION_TABLES,
    validate_symbol,
    normalize_symbol_to_internal,
    get_symbol_registry_table,
    get_active_symbols_query
)

class SymbolValidationMonitor:
    \"\"\"Monitor symbol format compliance and data consistency across all tables\"\"\"\n    \n    def __init__(self):\n        self.db_config = {\n            \"host\": os.getenv(\"MYSQL_HOST\", \"172.22.32.1\"),\n            \"port\": int(os.getenv(\"MYSQL_PORT\", \"3306\")),\n            \"user\": os.getenv(\"MYSQL_USER\", \"news_collector\"),\n            \"password\": os.getenv(\"MYSQL_PASSWORD\", \"99Rules!\"),\n            \"autocommit\": True,\n            \"charset\": 'utf8mb4'\n        }\n        \n        self.alert_thresholds = {\n            \"max_invalid_symbols_pct\": 5.0,     # Alert if >5% symbols are invalid\n            \"max_orphaned_symbols\": 10,         # Alert if >10 orphaned symbols\n            \"max_missing_symbols\": 5,           # Alert if >5 expected symbols missing\n            \"data_freshness_hours\": 6           # Alert if no new data in 6 hours\n        }\n        \n        self.monitoring_results = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"status\": \"UNKNOWN\",\n            \"issues\": [],\n            \"statistics\": {},\n            \"recommendations\": []\n        }\n    \n    def get_db_connection(self):\n        \"\"\"Get database connection\"\"\"\n        return mysql.connector.connect(**self.db_config)\n    \n    def check_crypto_assets_integrity(self):\n        \"\"\"Check crypto_assets table integrity and symbol format compliance\"\"\"\n        print(\"\\nüîç Checking crypto_assets table integrity...\")\n        \n        conn = self.get_db_connection()\n        cursor = conn.cursor(dictionary=True)\n        \n        # Basic statistics\n        cursor.execute(f\"SELECT COUNT(*) as total FROM {get_symbol_registry_table()}\")\n        total_assets = cursor.fetchone()['total']\n        \n        cursor.execute(f\"SELECT COUNT(*) as active FROM {get_symbol_registry_table()} WHERE is_active = 1\")\n        active_assets = cursor.fetchone()['active']\n        \n        # Symbol format validation\n        cursor.execute(f\"\"\"\n            SELECT symbol FROM {get_symbol_registry_table()}\n            WHERE is_active = 1\n        \"\"\")\n        \n        symbols = [row['symbol'] for row in cursor.fetchall()]\n        invalid_symbols = []\n        \n        for symbol in symbols:\n            validation = validate_symbol(symbol)\n            if not validation['valid']:\n                invalid_symbols.append({\n                    'symbol': symbol,\n                    'issues': validation['issues']\n                })\n        \n        invalid_pct = (len(invalid_symbols) / len(symbols)) * 100 if symbols else 0\n        \n        # Check for missing required fields\n        cursor.execute(f\"\"\"\n            SELECT \n                COUNT(*) as missing_coingecko,\n                (COUNT(*) / (SELECT COUNT(*) FROM {get_symbol_registry_table()} WHERE is_active = 1)) * 100 as missing_pct\n            FROM {get_symbol_registry_table()}\n            WHERE is_active = 1 AND (coingecko_id IS NULL OR coingecko_id = '')\n        \"\"\")\n        missing_data = cursor.fetchone()\n        \n        # Store results\n        self.monitoring_results['statistics']['crypto_assets'] = {\n            'total_assets': total_assets,\n            'active_assets': active_assets,\n            'invalid_symbols': len(invalid_symbols),\n            'invalid_symbols_pct': invalid_pct,\n            'missing_coingecko_pct': missing_data['missing_pct']\n        }\n        \n        # Check thresholds\n        if invalid_pct > self.alert_thresholds['max_invalid_symbols_pct']:\n            self.monitoring_results['issues'].append({\n                'severity': 'HIGH',\n                'type': 'INVALID_SYMBOLS',\n                'message': f'{invalid_pct:.1f}% of symbols have invalid format (threshold: {self.alert_thresholds[\"max_invalid_symbols_pct\"]}%)',\n                'details': invalid_symbols[:5]  # Show first 5 examples\n            })\n        \n        cursor.close()\n        conn.close()\n        \n        print(f\"   ‚úÖ Total assets: {total_assets:,} ({active_assets:,} active)\")\n        print(f\"   üìä Invalid symbols: {len(invalid_symbols):,} ({invalid_pct:.1f}%)\")\n        \n        if invalid_symbols:\n            print(f\"   ‚ö†Ô∏è  Examples: {', '.join([s['symbol'] for s in invalid_symbols[:3]])}\")\n    \n    def check_cross_table_consistency(self):\n        \"\"\"Check symbol consistency across all collection tables\"\"\"\n        print(\"\\nüîç Checking cross-table symbol consistency...\")\n        \n        conn = self.get_db_connection()\n        cursor = conn.cursor(dictionary=True)\n        \n        # Get reference symbols from crypto_assets\n        cursor.execute(get_active_symbols_query())\n        reference_symbols = set(row['symbol'] for row in cursor.fetchall())\n        \n        # Check each collection table\n        table_checks = [\n            (\"crypto_prices.price_data_real\", \"symbol\"),\n            (\"crypto_prices.technical_indicators\", \"symbol\"),\n            (\"crypto_prices.crypto_onchain_data\", \"coin_symbol\"),\n            (\"crypto_prices.real_time_sentiment_signals\", \"symbol\"),\n            (\"crypto_prices.ohlc_data\", \"symbol\"),\n            (\"crypto_prices.ml_features_materialized\", \"symbol\"),\n            (\"crypto_prices.trading_signals\", \"symbol\")\n        ]\n        \n        consistency_results = {}\n        total_orphaned = 0\n        total_missing = 0\n        \n        for table, symbol_col in table_checks:\n            try:\n                # Get unique symbols from this table\n                cursor.execute(f\"SELECT DISTINCT {symbol_col} as symbol FROM {table} WHERE {symbol_col} IS NOT NULL\")\n                table_symbols = set(row['symbol'] for row in cursor.fetchall())\n                \n                # Calculate consistency metrics\n                orphaned = table_symbols - reference_symbols  # In table but not in crypto_assets\n                missing = reference_symbols - table_symbols    # In crypto_assets but not in table\n                common = table_symbols & reference_symbols     # In both\n                \n                consistency_results[table] = {\n                    'total_symbols': len(table_symbols),\n                    'common_symbols': len(common),\n                    'orphaned_symbols': len(orphaned),\n                    'missing_symbols': len(missing),\n                    'consistency_pct': (len(common) / len(reference_symbols)) * 100 if reference_symbols else 0\n                }\n                \n                total_orphaned += len(orphaned)\n                total_missing += len(missing)\n                \n                print(f\"   üìã {table}:\")\n                print(f\"      Symbols: {len(table_symbols):,} | Common: {len(common):,} | Orphaned: {len(orphaned):,} | Missing: {len(missing):,}\")\n                \n                # Store significant issues\n                if len(orphaned) > self.alert_thresholds['max_orphaned_symbols']:\n                    self.monitoring_results['issues'].append({\n                        'severity': 'MEDIUM',\n                        'type': 'ORPHANED_SYMBOLS',\n                        'table': table,\n                        'message': f'{len(orphaned)} orphaned symbols in {table}',\n                        'details': list(orphaned)[:10]\n                    })\n                \n                if len(missing) > self.alert_thresholds['max_missing_symbols']:\n                    self.monitoring_results['issues'].append({\n                        'severity': 'MEDIUM', \n                        'type': 'MISSING_SYMBOLS',\n                        'table': table,\n                        'message': f'{len(missing)} expected symbols missing from {table}',\n                        'details': list(missing)[:10]\n                    })\n                \n            except Exception as e:\n                print(f\"   ‚ùå {table}: Error - {e}\")\n                consistency_results[table] = {'error': str(e)}\n        \n        self.monitoring_results['statistics']['cross_table_consistency'] = consistency_results\n        self.monitoring_results['statistics']['total_orphaned_symbols'] = total_orphaned\n        self.monitoring_results['statistics']['total_missing_symbols'] = total_missing\n        \n        cursor.close()\n        conn.close()\n        \n        print(f\"   üìä Total orphaned symbols across tables: {total_orphaned:,}\")\n        print(f\"   üìä Total missing symbols across tables: {total_missing:,}\")\n    \n    def check_data_freshness(self):\n        \"\"\"Check data freshness for each collection table\"\"\"\n        print(\"\\nüîç Checking data freshness...\")\n        \n        conn = self.get_db_connection()\n        cursor = conn.cursor(dictionary=True)\n        \n        freshness_threshold = datetime.now() - timedelta(hours=self.alert_thresholds['data_freshness_hours'])\n        \n        tables_to_check = [\n            (\"crypto_prices.price_data_real\", \"timestamp_iso\"),\n            (\"crypto_prices.technical_indicators\", \"timestamp\"),\n            (\"crypto_prices.crypto_onchain_data\", \"timestamp\"),\n            (\"crypto_prices.real_time_sentiment_signals\", \"timestamp\"),\n            (\"crypto_news.news_data\", \"published_date\")\n        ]\n        \n        freshness_results = {}\n        \n        for table, timestamp_col in tables_to_check:\n            try:\n                cursor.execute(f\"\"\"\n                    SELECT \n                        MAX({timestamp_col}) as latest_timestamp,\n                        COUNT(*) as total_records,\n                        COUNT(DISTINCT CASE WHEN {timestamp_col} > %s THEN 1 END) as recent_records\n                    FROM {table}\n                    WHERE {timestamp_col} IS NOT NULL\n                \"\"\", (freshness_threshold,))\n                \n                result = cursor.fetchone()\n                \n                if result['latest_timestamp']:\n                    latest_dt = result['latest_timestamp']\n                    if isinstance(latest_dt, str):\n                        latest_dt = datetime.fromisoformat(latest_dt.replace('Z', '+00:00'))\n                    \n                    hours_since_update = (datetime.now() - latest_dt.replace(tzinfo=None)).total_seconds() / 3600\n                    \n                    freshness_results[table] = {\n                        'latest_timestamp': latest_dt.isoformat(),\n                        'hours_since_update': hours_since_update,\n                        'total_records': result['total_records'],\n                        'recent_records': result['recent_records']\n                    }\n                    \n                    print(f\"   üìÖ {table}: {hours_since_update:.1f}h ago ({result['total_records']:,} total records)\")\n                    \n                    if hours_since_update > self.alert_thresholds['data_freshness_hours']:\n                        self.monitoring_results['issues'].append({\n                            'severity': 'HIGH',\n                            'type': 'STALE_DATA',\n                            'table': table,\n                            'message': f'No new data in {hours_since_update:.1f} hours (threshold: {self.alert_thresholds[\"data_freshness_hours\"]}h)',\n                            'latest_timestamp': latest_dt.isoformat()\n                        })\n                else:\n                    print(f\"   ‚ùå {table}: No timestamp data found\")\n                    freshness_results[table] = {'error': 'No timestamp data'}\n            \n            except Exception as e:\n                print(f\"   ‚ùå {table}: Error - {e}\")\n                freshness_results[table] = {'error': str(e)}\n        \n        self.monitoring_results['statistics']['data_freshness'] = freshness_results\n        cursor.close()\n        conn.close()\n    \n    def generate_recommendations(self):\n        \"\"\"Generate actionable recommendations based on monitoring results\"\"\"\n        recommendations = []\n        \n        # Check for invalid symbols\n        if 'crypto_assets' in self.monitoring_results['statistics']:\n            stats = self.monitoring_results['statistics']['crypto_assets']\n            if stats['invalid_symbols'] > 0:\n                recommendations.append({\n                    'priority': 'HIGH',\n                    'action': 'Symbol Format Cleanup',\n                    'description': f\"Fix {stats['invalid_symbols']} invalid symbols in crypto_assets table\",\n                    'command': 'python analyze_historical_symbol_normalization.py'\n                })\n        \n        # Check for orphaned symbols\n        total_orphaned = self.monitoring_results['statistics'].get('total_orphaned_symbols', 0)\n        if total_orphaned > 10:\n            recommendations.append({\n                'priority': 'MEDIUM',\n                'action': 'Remove Orphaned Symbols', \n                'description': f'Clean up {total_orphaned} orphaned symbols across collection tables',\n                'impact': 'Improves data consistency and query performance'\n            })\n        \n        # Check for missing symbols\n        total_missing = self.monitoring_results['statistics'].get('total_missing_symbols', 0)\n        if total_missing > 20:\n            recommendations.append({\n                'priority': 'MEDIUM',\n                'action': 'Backfill Missing Symbols',\n                'description': f'Collect data for {total_missing} missing symbols',\n                'impact': 'Improves data coverage and completeness'\n            })\n        \n        # Check for stale data\n        stale_issues = [i for i in self.monitoring_results['issues'] if i['type'] == 'STALE_DATA']\n        if stale_issues:\n            recommendations.append({\n                'priority': 'HIGH',\n                'action': 'Investigate Collection Issues',\n                'description': f'Check {len(stale_issues)} tables with stale data',\n                'affected_tables': [i['table'] for i in stale_issues]\n            })\n        \n        self.monitoring_results['recommendations'] = recommendations\n        \n        if recommendations:\n            print(f\"\\nüí° RECOMMENDATIONS:\")\n            for i, rec in enumerate(recommendations, 1):\n                print(f\"   {i}. [{rec['priority']}] {rec['action']}\")\n                print(f\"      {rec['description']}\")\n    \n    def determine_overall_status(self):\n        \"\"\"Determine overall system status based on issues found\"\"\"\n        issues = self.monitoring_results['issues']\n        \n        if not issues:\n            status = 'HEALTHY'\n        elif any(i['severity'] == 'HIGH' for i in issues):\n            status = 'CRITICAL'\n        elif any(i['severity'] == 'MEDIUM' for i in issues):\n            status = 'WARNING'\n        else:\n            status = 'MINOR_ISSUES'\n        \n        self.monitoring_results['status'] = status\n        \n        status_emoji = {\n            'HEALTHY': '‚úÖ',\n            'MINOR_ISSUES': '‚ö†Ô∏è ',\n            'WARNING': 'üü°',\n            'CRITICAL': 'üî¥'\n        }\n        \n        print(f\"\\n{status_emoji.get(status, '‚ùì')} OVERALL STATUS: {status}\")\n        \n        if issues:\n            print(f\"   Issues found: {len(issues)}\")\n            for issue in issues:\n                print(f\"   ‚Ä¢ [{issue['severity']}] {issue['message']}\")\n    \n    def save_monitoring_report(self):\n        \"\"\"Save monitoring results to file\"\"\"\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        filename = f'symbol_monitoring_report_{timestamp}.json'\n        \n        with open(filename, 'w') as f:\n            json.dump(self.monitoring_results, f, indent=2, default=str)\n        \n        print(f\"\\nüìÑ Monitoring report saved: {filename}\")\n        return filename\n    \n    def run_full_monitoring(self):\n        \"\"\"Run complete monitoring cycle\"\"\"\n        print(\"üöÄ SYMBOL VALIDATION MONITORING\")\n        print(f\"Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n        print(\"=\" * 80)\n        \n        try:\n            self.check_crypto_assets_integrity()\n            self.check_cross_table_consistency()\n            self.check_data_freshness()\n            self.generate_recommendations()\n            self.determine_overall_status()\n            \n            report_file = self.save_monitoring_report()\n            \n            print(f\"\\n‚úÖ Monitoring completed successfully!\")\n            return self.monitoring_results\n            \n        except Exception as e:\n            print(f\"\\n‚ùå Monitoring failed: {e}\")\n            self.monitoring_results['status'] = 'ERROR'\n            self.monitoring_results['error'] = str(e)\n            return self.monitoring_results\n\ndef main():\n    \"\"\"Main monitoring execution\"\"\"\n    monitor = SymbolValidationMonitor()\n    results = monitor.run_full_monitoring()\n    \n    # If running as a monitoring service, you could add:\n    # - Send alerts via email/Slack if status is CRITICAL\n    # - Store results in monitoring database\n    # - Generate trends over time\n    # - Integration with Prometheus/Grafana\n    \n    return results\n\nif __name__ == \"__main__\":\n    main()\n