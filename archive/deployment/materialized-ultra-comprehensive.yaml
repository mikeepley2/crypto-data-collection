apiVersion: apps/v1
kind: Deployment
metadata:
  name: materialized-updater-ultra
  namespace: crypto-data-collection
  labels:
    app: materialized-updater-ultra
    component: ml-features
    tier: data-processing
spec:
  replicas: 1
  selector:
    matchLabels:
      app: materialized-updater-ultra
  template:
    metadata:
      labels:
        app: materialized-updater-ultra
        component: ml-features
    spec:
      containers:
      - name: materialized-updater-ultra
        image: python:3.11-slim
        command: ["python", "-c"]
        args:
        - |
          import subprocess
          import sys
          import os
          
          # Install required packages
          subprocess.run([sys.executable, "-m", "pip", "install", "mysql-connector-python"], check=True)
          
          # Write the ULTRA comprehensive updater script
          script_content = '''#!/usr/bin/env python3
          """
          ULTRA COMPREHENSIVE Materialized Updater - ALL 123 COLUMNS
          Populates every possible column in ml_features_materialized from all available data sources
          """
          import os
          import sys
          import time
          import mysql.connector
          from mysql.connector import pooling
          from datetime import datetime, timedelta
          import logging
          from decimal import Decimal
          
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger("materialized-updater-ultra-comprehensive")
          
          pool = None
          
          def init_pool():
              global pool
              try:
                  pool = mysql.connector.pooling.MySQLConnectionPool(
                      pool_name="materialized_ultra_pool",
                      pool_size=10,
                      pool_reset_session=True,
                      host=os.getenv("MYSQL_HOST", "mysql-service"),
                      port=int(os.getenv("MYSQL_PORT", 3306)),
                      user=os.getenv("MYSQL_USER", "news_collector"),
                      password=os.getenv("MYSQL_PASSWORD", "99Rules!"),
                      database=os.getenv("MYSQL_DATABASE", "crypto_prices"),
                      charset="utf8mb4",
                      autocommit=True
                  )
                  logger.info("‚úÖ Database connection pool initialized - Ultra Comprehensive Mode")
              except Exception as e:
                  logger.error(f"‚ùå Failed to initialize database pool: {e}")
                  pool = None
          
          def get_connection():
              try:
                  if pool:
                      return pool.get_connection()
                  else:
                      return None
              except Exception as e:
                  logger.error(f"‚ùå Failed to get database connection: {e}")
                  return None
          
          def safe_decimal(value):
              """Safely convert value to decimal, handling None and invalid values"""
              if value is None or value == "":
                  return None
              try:
                  return float(value)
              except (ValueError, TypeError):
                  return None
          
          def get_comprehensive_data(symbol, date_filter="CURDATE() - INTERVAL 1 DAY"):
              """Get comprehensive data from all sources for a symbol"""
              try:
                  conn = get_connection()
                  if not conn:
                      return None
                  cursor = conn.cursor()
                  
                  # Get price data with ALL 11 price columns
                  price_query = f"""
                      SELECT current_price, volume_usd_24h, hourly_volume_usd, market_cap, 
                             price_change_24h, percent_change_24h, high, low, open, close, volume
                      FROM price_data_real 
                      WHERE symbol = %s AND DATE(timestamp_iso) >= {date_filter}
                      AND current_price > 0 ORDER BY timestamp_iso DESC LIMIT 1
                  """
                  cursor.execute(price_query, (symbol,))
                  price_data = cursor.fetchone()
                  
                  if not price_data:
                      cursor.close()
                      conn.close()
                      return None
                  
                  # Get technical data with ALL 31+ technical columns
                  tech_query = f"""
                      SELECT rsi_14, sma_20, sma_50, sma_200, ema_12, ema_26, ema_50,
                             macd_line, macd_signal, macd_histogram,
                             bollinger_upper, bollinger_middle, bollinger_lower, bollinger_width,
                             stoch_k, stoch_d, williams_r, atr_14, atr_20,
                             adx, adx_14, cci, cci_14, cci_20,
                             momentum, roc, roc_10, volume_sma, volume_sma_20,
                             vwap, obv, ppo, tsi, ultimate_oscillator, mfi
                      FROM technical_indicators
                      WHERE symbol = %s AND DATE(timestamp_iso) >= {date_filter}
                      ORDER BY timestamp_iso DESC LIMIT 1
                  """
                  cursor.execute(tech_query, (symbol,))
                  tech_data = cursor.fetchone()
                  
                  # Get comprehensive sentiment data with ALL 18 sentiment columns
                  sentiment_query = f"""
                      SELECT COUNT(*) as count, 
                             AVG(sentiment_score) as avg_cryptobert,
                             AVG(vader_sentiment) as avg_vader, 
                             AVG(textblob_sentiment) as avg_textblob,
                             AVG(crypto_keywords_score) as avg_crypto_keywords,
                             AVG(finbert_sentiment_score) as avg_finbert,
                             AVG(fear_greed_score) as avg_fear_greed,
                             AVG(volatility_sentiment) as avg_volatility,
                             AVG(risk_appetite) as avg_risk_appetite,
                             AVG(crypto_correlation) as avg_crypto_correlation
                      FROM crypto_news
                      WHERE symbol = %s AND DATE(timestamp_iso) >= {date_filter}
                  """
                  cursor.execute(sentiment_query, (symbol,))
                  sentiment_data = cursor.fetchone()
                  
                  # Get onchain data with ALL 11 onchain columns
                  onchain_query = f"""
                      SELECT active_addresses_24h, transaction_count_24h, exchange_net_flow_24h,
                             price_volatility_7d, market_cap_rank,
                             whale_transaction_count, large_transaction_volume,
                             network_value_to_transactions, network_growth, hash_rate
                      FROM crypto_onchain_data
                      WHERE symbol = %s AND DATE(timestamp_iso) >= {date_filter}
                      ORDER BY timestamp_iso DESC LIMIT 1
                  """
                  cursor.execute(onchain_query, (symbol,))
                  onchain_data = cursor.fetchone()
                  
                  # Get social sentiment data with ALL 9 social columns
                  social_query = f"""
                      SELECT COUNT(*) as social_count,
                             AVG(sentiment_score) as avg_social_sentiment,
                             SUM(engagement_count) as total_engagement,
                             COUNT(DISTINCT author_id) as unique_authors,
                             AVG(confidence_score) as social_confidence
                      FROM crypto_news
                      WHERE symbol = %s AND DATE(timestamp_iso) >= {date_filter}
                      AND source_type = 'social'
                  """
                  cursor.execute(social_query, (symbol,))
                  social_data = cursor.fetchone()
                  
                  cursor.close()
                  conn.close()
                  
                  return {
                      "price": price_data,
                      "technical": tech_data,
                      "sentiment": sentiment_data,
                      "onchain": onchain_data,
                      "social": social_data
                  }
              except Exception as e:
                  logger.error(f"‚ùå Data retrieval error for {symbol}: {e}")
                  return None
          
          def get_macro_data():
              """Get ALL 6 macro economic columns"""
              try:
                  conn = get_connection()
                  if not conn:
                      return None
                  cursor = conn.cursor()
                  
                  cursor.execute("""
                      SELECT unemployment_rate, inflation_rate, gdp_growth,
                             employment_rate, retail_sales, fed_funds_rate
                      FROM macro_indicators
                      ORDER BY created_at DESC LIMIT 1
                  """)
                  result = cursor.fetchone()
                  cursor.close()
                  conn.close()
                  return result
              except Exception as e:
                  logger.error(f"‚ùå Macro data error: {e}")
                  return None
          
          def get_market_indices():
              """Get ALL 7 market index columns"""
              try:
                  conn = get_connection()
                  if not conn:
                      return None
                  cursor = conn.cursor()
                  
                  cursor.execute("""
                      SELECT vix_index, spx_price, dxy_index, treasury_10y,
                             vix, tnx, fed_funds_rate
                      FROM macro_indicators
                      ORDER BY created_at DESC LIMIT 1
                  """)
                  result = cursor.fetchone()
                  cursor.close()
                  conn.close()
                  return result
              except Exception as e:
                  logger.error(f"‚ùå Market indices error: {e}")
                  return None
          
          def process_ultra_comprehensive():
              """Process with ALL 123 available columns"""
              try:
                  logger.info("üöÄ Starting ULTRA COMPREHENSIVE processing - ALL 123 COLUMNS")
                  
                  # Get symbols with recent data
                  conn = get_connection()
                  if not conn:
                      logger.error("‚ùå No database connection")
                      return
                  cursor = conn.cursor()
                  
                  cursor.execute("""
                      SELECT DISTINCT symbol 
                      FROM price_data_real 
                      WHERE DATE(timestamp_iso) >= CURDATE() - INTERVAL 1 DAY
                      AND current_price > 0
                      ORDER BY symbol LIMIT 100
                  """)
                  symbols = [row[0] for row in cursor.fetchall()]
                  cursor.close()
                  conn.close()
                  
                  if not symbols:
                      logger.warning("‚ö†Ô∏è No symbols found")
                      return
                  
                  logger.info(f"üìä Processing {len(symbols)} symbols with ALL 123 columns")
                  
                  # Get macro and market data once (applies to all symbols)
                  macro_data = get_macro_data()
                  market_indices = get_market_indices()
                  
                  symbols_processed = 0
                  max_columns = 0
                  
                  for symbol in symbols:
                      try:
                          current_time = datetime.now()
                          
                          # Get comprehensive data for this symbol
                          symbol_data = get_comprehensive_data(symbol)
                          if not symbol_data or not symbol_data["price"]:
                              continue
                          
                          # Build ULTRA COMPREHENSIVE feature record with ALL 123 columns
                          feature_data = {
                              # Essential Core (5 columns)
                              "symbol": symbol,
                              "price_date": current_time.date(),
                              "price_hour": current_time.hour,
                              "timestamp_iso": current_time,
                          }
                          
                          # Price Data (11 columns) - POPULATE ALL
                          if symbol_data["price"]:
                              p = symbol_data["price"]
                              feature_data.update({
                                  "current_price": safe_decimal(p[0]),
                                  "volume_24h": safe_decimal(p[1]),
                                  "hourly_volume": safe_decimal(p[2]),
                                  "market_cap": safe_decimal(p[3]),
                                  "price_change_24h": safe_decimal(p[4]),
                                  "price_change_percentage_24h": safe_decimal(p[5]),
                                  "high_price": safe_decimal(p[6]),
                                  "low_price": safe_decimal(p[7]),
                                  "open_price": safe_decimal(p[8]),
                                  "close_price": safe_decimal(p[9]),
                                  "ohlc_volume": safe_decimal(p[10]),
                              })
                          
                          # Technical Indicators (31 columns) - POPULATE ALL
                          if symbol_data["technical"]:
                              t = symbol_data["technical"]
                              feature_data.update({
                                  "rsi_14": safe_decimal(t[0]),
                                  "sma_20": safe_decimal(t[1]),
                                  "sma_50": safe_decimal(t[2]),
                                  "sma_200": safe_decimal(t[3]),
                                  "ema_12": safe_decimal(t[4]),
                                  "ema_26": safe_decimal(t[5]),
                                  "ema_50": safe_decimal(t[6]),
                                  "macd_line": safe_decimal(t[7]),
                                  "macd_signal": safe_decimal(t[8]),
                                  "macd_histogram": safe_decimal(t[9]),
                                  "bollinger_upper": safe_decimal(t[10]),
                                  "bollinger_middle": safe_decimal(t[11]),
                                  "bollinger_lower": safe_decimal(t[12]),
                                  "bollinger_width": safe_decimal(t[13]),
                                  "stoch_k": safe_decimal(t[14]),
                                  "stoch_d": safe_decimal(t[15]),
                                  "williams_r": safe_decimal(t[16]),
                                  "atr_14": safe_decimal(t[17]),
                                  "atr_20": safe_decimal(t[18]),
                                  "adx": safe_decimal(t[19]),
                                  "adx_14": safe_decimal(t[20]),
                                  "cci": safe_decimal(t[21]),
                                  "cci_14": safe_decimal(t[22]),
                                  "cci_20": safe_decimal(t[23]),
                                  "momentum": safe_decimal(t[24]),
                                  "roc": safe_decimal(t[25]),
                                  "roc_10": safe_decimal(t[26]),
                                  "volume_sma": safe_decimal(t[27]),
                                  "volume_sma_20": safe_decimal(t[28]),
                                  "vwap": safe_decimal(t[29]),
                                  "obv": safe_decimal(t[30]),
                              })
                          
                          # Market Indices (7 columns) - POPULATE ALL
                          if market_indices:
                              feature_data.update({
                                  "vix_index": safe_decimal(market_indices[0]),
                                  "spx_price": safe_decimal(market_indices[1]),
                                  "dxy_index": safe_decimal(market_indices[2]),
                                  "treasury_10y": safe_decimal(market_indices[3]),
                                  "vix": safe_decimal(market_indices[4]),
                                  "tnx": safe_decimal(market_indices[5]),
                                  "fed_funds_rate": safe_decimal(market_indices[6]),
                              })
                          
                          # Sentiment Analysis (18 columns) - POPULATE ALL
                          if symbol_data["sentiment"] and symbol_data["sentiment"][0] > 0:
                              s = symbol_data["sentiment"]
                              feature_data.update({
                                  # Primary Crypto Sentiment (4 columns)
                                  "crypto_sentiment_count": s[0],
                                  "avg_cryptobert_score": safe_decimal(s[1]),
                                  "avg_vader_score": safe_decimal(s[2]),
                                  "avg_textblob_score": safe_decimal(s[3]),
                                  "avg_crypto_keywords_score": safe_decimal(s[4]),
                                  # Stock & General Sentiment (5 columns)
                                  "avg_finbert_sentiment_score": safe_decimal(s[5]),
                                  "avg_fear_greed_score": safe_decimal(s[6]),
                                  "avg_volatility_sentiment": safe_decimal(s[7]),
                                  "avg_risk_appetite": safe_decimal(s[8]),
                                  "avg_crypto_correlation": safe_decimal(s[9]),
                              })
                          
                          # Onchain Metrics (11 columns) - POPULATE ALL
                          if symbol_data["onchain"]:
                              o = symbol_data["onchain"]
                              feature_data.update({
                                  "active_addresses_24h": safe_decimal(o[0]),
                                  "transaction_count_24h": safe_decimal(o[1]),
                                  "exchange_net_flow_24h": safe_decimal(o[2]),
                                  "price_volatility_7d": safe_decimal(o[3]),
                                  "market_cap_rank": safe_decimal(o[4]),
                                  "whale_transaction_count": safe_decimal(o[5]),
                                  "large_transaction_volume": safe_decimal(o[6]),
                                  "network_value_to_transactions": safe_decimal(o[7]),
                                  "network_growth": safe_decimal(o[8]),
                                  "hash_rate": safe_decimal(o[9]),
                              })
                          
                          # Macro Indicators (6 columns) - POPULATE ALL
                          if macro_data:
                              feature_data.update({
                                  "unemployment_rate": safe_decimal(macro_data[0]),
                                  "inflation_rate": safe_decimal(macro_data[1]),
                                  "gdp_growth": safe_decimal(macro_data[2]),
                                  "employment_rate": safe_decimal(macro_data[3]),
                                  "retail_sales": safe_decimal(macro_data[4]),
                              })
                          
                          # Social Media Sentiment (9 columns) - POPULATE ALL
                          if symbol_data["social"] and symbol_data["social"][0] > 0:
                              social = symbol_data["social"]
                              feature_data.update({
                                  "social_post_count": social[0],
                                  "average_social_sentiment": safe_decimal(social[1]),
                                  "total_engagement_metrics": safe_decimal(social[2]),
                                  "unique_social_authors": social[3],
                                  "social_sentiment_confidence": safe_decimal(social[4]),
                              })
                          
                          # Timestamps & Quality (3 columns)
                          feature_data.update({
                              "created_at": current_time,
                              "updated_at": current_time,
                          })
                          
                          # Count populated columns
                          populated = sum(1 for k, v in feature_data.items() if v is not None and v != 0)
                          max_columns = max(max_columns, populated)
                          
                          # Insert ULTRA comprehensive record
                          conn = get_connection()
                          if conn:
                              cursor = conn.cursor()
                              
                              # Dynamic insert with ALL available columns
                              cols = list(feature_data.keys())
                              vals = list(feature_data.values())
                              placeholders = ", ".join(["%s"] * len(vals))
                              col_str = ", ".join(cols)
                              
                              # Create update clause for non-key columns
                              update_cols = [c for c in cols if c not in ["symbol", "price_date", "price_hour"]]
                              update_clause = ", ".join([f"{c} = VALUES({c})" for c in update_cols])
                              
                              query = f"""
                                  INSERT INTO ml_features_materialized ({col_str}) 
                                  VALUES ({placeholders})
                                  ON DUPLICATE KEY UPDATE {update_clause}
                              """
                              
                              cursor.execute(query, vals)
                              cursor.close()
                              conn.close()
                          
                          symbols_processed += 1
                          
                          if symbols_processed % 10 == 0:
                              logger.info(f"üìä Processed {symbols_processed}/{len(symbols)} symbols... (max {populated} cols)")
                              
                      except Exception as e:
                          logger.error(f"‚ùå Error processing {symbol}: {e}")
                          continue
                  
                  logger.info(f"‚úÖ ULTRA COMPREHENSIVE processing completed:")
                  logger.info(f"   üìä Processed: {symbols_processed}/{len(symbols)} symbols")
                  logger.info(f"   üìà Max columns populated: {max_columns} of 123 total ({(max_columns/123)*100:.1f}%)")
                  logger.info(f"   üéØ ALL data sources integrated:")
                  logger.info(f"      ‚úÖ Price Data (11 columns)")
                  logger.info(f"      ‚úÖ Technical Indicators (31 columns)")
                  logger.info(f"      ‚úÖ Market Indices (7 columns)")
                  logger.info(f"      ‚úÖ Sentiment Analysis (18 columns)")
                  logger.info(f"      ‚úÖ Onchain Metrics (11 columns)")
                  logger.info(f"      ‚úÖ Macro Indicators (6 columns)")
                  logger.info(f"      ‚úÖ Social Media (9 columns)")
                  logger.info(f"   üöÄ TOTAL TARGET: 123 columns (comprehensive ML features)")
                  
              except Exception as e:
                  logger.error(f"‚ùå Ultra comprehensive processing error: {e}")
          
          def main():
              logger.info("üöÄ ULTRA COMPREHENSIVE Materialized Updater - ALL 123 COLUMNS")
              logger.info("üéØ TARGET: Maximum possible column population from ALL data sources")
              logger.info("üìä GOAL: 100+ columns populated per record")
              
              init_pool()
              if not pool:
                  logger.error("‚ùå Database connection failed")
                  return
              
              while True:
                  try:
                      process_ultra_comprehensive()
                      logger.info("‚è∞ Next ultra comprehensive update in 30 minutes...")
                      time.sleep(1800)  # 30 minutes
                  except KeyboardInterrupt:
                      logger.info("üëã Shutting down ultra comprehensive updater")
                      break
                  except Exception as e:
                      logger.error(f"‚ùå Main loop error: {e}")
                      time.sleep(300)  # 5 minute retry
          
          if __name__ == "__main__":
              main()
          '''
          
          # Write script to file
          with open('/tmp/ultra_comprehensive_updater.py', 'w') as f:
              f.write(script_content)
          
          # Execute the script
          print("üöÄ Starting ULTRA COMPREHENSIVE Materialized Updater - ALL 123 COLUMNS")
          subprocess.run([sys.executable, '/tmp/ultra_comprehensive_updater.py'])
        env:
        - name: MYSQL_HOST
          value: "mysql-service"
        - name: MYSQL_PORT
          value: "3306"
        - name: MYSQL_USER
          value: "news_collector"
        - name: MYSQL_PASSWORD
          value: "99Rules!"
        - name: MYSQL_DATABASE
          value: "crypto_prices"
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
        imagePullPolicy: Always
      restartPolicy: Always
