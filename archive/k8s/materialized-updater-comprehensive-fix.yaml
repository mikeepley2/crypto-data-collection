apiVersion: v1
kind: ConfigMap
metadata:
  name: materialized-updater-code
  namespace: crypto-data-collection
data:
  materialized_updater.py: |
    #!/usr/bin/env python3
    """
    Comprehensive Materialized Updater with Real Data Population
    """

    import os
    import time
    import mysql.connector
    from mysql.connector import pooling
    from datetime import datetime, timedelta
    import logging
    import threading

    # Configure logging
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    logger = logging.getLogger('materialized-updater')

    # Database connection pool
    pool = None

    def init_pool():
        """Initialize database connection pool"""
        global pool
        try:
            pool = mysql.connector.pooling.MySQLConnectionPool(
                pool_name="materialized_pool",
                pool_size=3,
                pool_reset_session=True,
                host=os.getenv("DB_HOST", "127.0.0.1"),
                user=os.getenv("DB_USER", "news_collector"),
                password=os.getenv("DB_PASSWORD", "99Rules!"),
                database=os.getenv("DB_NAME", "crypto_prices"),
                autocommit=True
            )
            logger.info("Database connection pool initialized")
        except Exception as e:
            logger.error(f"Failed to initialize connection pool: {e}")
            raise

    def get_connection():
        """Get connection from pool"""
        try:
            return pool.get_connection()
        except Exception as e:
            logger.error(f"Failed to get connection from pool: {e}")
            return None

    def get_latest_macro_data(cursor):
        """Get latest macro data from macro_indicators table"""
        macro_data = {}
        try:
            # Map macro indicator names to materialized table columns
            macro_mapping = {
                'VIX': 'vix',
                'US_10Y_YIELD': 'treasury_10y',
                'DXY': 'dxy',
                'US_UNEMPLOYMENT': 'unemployment_rate',
                'US_INFLATION': 'inflation_rate',
                'GOLD_PRICE': 'gold_price',
                'OIL_PRICE': 'oil_price'
            }
            
            # Get latest values for each indicator
            for indicator_name, column_name in macro_mapping.items():
                cursor.execute("""
                    SELECT value, indicator_date
                    FROM macro_indicators 
                    WHERE indicator_name = %s
                    ORDER BY indicator_date DESC
                    LIMIT 1
                """, (indicator_name,))
                
                result = cursor.fetchone()
                if result:
                    macro_data[column_name] = result[0]
                    logger.debug(f"Found {indicator_name}: {result[0]} (date: {result[1]})")
                else:
                    logger.debug(f"No data found for {indicator_name}")
            
            return macro_data
        except Exception as e:
            logger.error(f"Error getting macro data: {e}")
            return {}

    def get_technical_data(cursor, symbol, timestamp_iso):
        """Get technical data from price_data_real"""
        try:
            cursor.execute("""
                SELECT sma_20, rsi_14, macd, macd_signal, macd_histogram, 
                       bb_upper, bb_middle, bb_lower
                FROM price_data_real 
                WHERE symbol = %s 
                AND timestamp_iso = %s
            """, (symbol, timestamp_iso))
            
            result = cursor.fetchone()
            if result:
                return {
                    'sma_20': result[0],
                    'rsi_14': result[1],
                    'macd_line': result[2],
                    'macd_signal': result[3],
                    'macd_histogram': result[4],
                    'bb_upper': result[5],
                    'bb_middle': result[6],
                    'bb_lower': result[7]
                }
            return {}
        except Exception as e:
            logger.error(f"Error getting technical data for {symbol}: {e}")
            return {}

    def get_onchain_data(cursor, symbol, timestamp_iso):
        """Get onchain data with forward-fill strategy"""
        try:
            # Normalize symbol (remove -USD suffix)
            normalized_symbol = symbol.replace('-USD', '')
            
            # Look for onchain data within 24 hours
            cursor.execute("""
                SELECT active_addresses_24h, transaction_count_24h, exchange_net_flow_24h, price_volatility_7d
                FROM crypto_onchain_data 
                WHERE coin_symbol = %s 
                AND collection_date >= DATE_SUB(%s, INTERVAL 1 DAY)
                AND collection_date <= %s
                ORDER BY collection_date DESC
                LIMIT 1
            """, (normalized_symbol, timestamp_iso, timestamp_iso))
            
            result = cursor.fetchone()
            if result:
                return {
                    'active_addresses_24h': result[0],
                    'transaction_count_24h': result[1],
                    'exchange_net_flow_24h': result[2],
                    'price_volatility_7d': result[3]
                }
            return {}
        except Exception as e:
            logger.error(f"Error getting onchain data for {symbol}: {e}")
            return {}

    def get_sentiment_data(cursor, symbol, timestamp_iso):
        """Get sentiment data with time-based decay"""
        try:
            # Look for sentiment data within 24 hours
            cursor.execute("""
                SELECT ml_sentiment_score, published_at
                FROM crypto_news 
                WHERE symbol = %s 
                AND published_at >= DATE_SUB(%s, INTERVAL 24 HOUR)
                AND published_at <= %s
                AND ml_sentiment_score IS NOT NULL
                ORDER BY published_at DESC
            """, (symbol, timestamp_iso, timestamp_iso))
            
            results = cursor.fetchall()
            if not results:
                return {'avg_sentiment': None, 'sentiment_count': 0}
            
            # Calculate weighted average with time decay
            weighted_sum = 0
            total_weight = 0
            count = 0
            
            for sentiment_score, published_at in results:
                # Calculate time decay (more recent = higher weight)
                time_diff = (timestamp_iso - published_at).total_seconds() / 3600  # hours
                weight = max(0.1, 1.0 - (time_diff / 24.0))  # Decay over 24 hours
                
                weighted_sum += sentiment_score * weight
                total_weight += weight
                count += 1
            
            if total_weight > 0:
                avg_sentiment = weighted_sum / total_weight
                return {'avg_sentiment': avg_sentiment, 'sentiment_count': count}
            
            return {'avg_sentiment': None, 'sentiment_count': 0}
        except Exception as e:
            logger.error(f"Error getting sentiment data for {symbol}: {e}")
            return {'avg_sentiment': None, 'sentiment_count': 0}

    def get_daily_close_price(cursor, symbol, target_date):
        """Get the last price of the day for close price calculation"""
        try:
            cursor.execute("""
                SELECT current_price
                FROM price_data_real
                WHERE symbol = %s
                AND DATE(timestamp_iso) = %s
                ORDER BY timestamp_iso DESC
                LIMIT 1
            """, (symbol, target_date))
            
            result = cursor.fetchone()
            return result[0] if result else None
        except Exception as e:
            logger.error(f"Error getting close price for {symbol}: {e}")
            return None

    def update_materialized_table():
        """Main update function for materialized table"""
        conn = get_connection()
        if not conn:
            logger.error("Failed to get database connection")
            return
        
        try:
            cursor = conn.cursor()
            
            # Get latest macro data once per batch
            macro_data = get_latest_macro_data(cursor)
            logger.info(f"Loaded macro data: {list(macro_data.keys())}")
            
            # Get today's price data in batches
            cursor.execute("""
                SELECT symbol, timestamp_iso, current_price, price_change_24h, 
                       volume_usd_24h, market_cap
                FROM price_data_real 
                WHERE DATE(timestamp_iso) = CURDATE()
                ORDER BY symbol, timestamp_iso
                LIMIT 1000
            """)
            
            price_records = cursor.fetchall()
            logger.info(f"Processing {len(price_records)} price records")
            
            updates = 0
            inserts = 0
            
            for symbol, timestamp_iso, current_price, price_change_24h, volume_usd_24h, market_cap in price_records:
                try:
                    # Get price date and hour
                    price_date = timestamp_iso.date()
                    price_hour = timestamp_iso.hour
                    
                    # Get technical data
                    tech_data = get_technical_data(cursor, symbol, timestamp_iso)
                    
                    # Get onchain data
                    onchain_data = get_onchain_data(cursor, symbol, timestamp_iso)
                    
                    # Get sentiment data
                    sentiment_data = get_sentiment_data(cursor, symbol, timestamp_iso)
                    
                    # Get close price
                    close_price = get_daily_close_price(cursor, symbol, price_date)
                    
                    # Prepare data for insert/update
                    insert_data = {
                        'symbol': symbol,
                        'price_date': price_date,
                        'price_hour': price_hour,
                        'timestamp_iso': timestamp_iso,
                        'current_price': current_price,
                        'price_change_24h': price_change_24h,
                        'volume_24h': volume_usd_24h,
                        'market_cap': market_cap,
                        'avg_ml_overall_sentiment': sentiment_data.get('avg_sentiment'),
                        'sentiment_volume': sentiment_data.get('sentiment_count', 0),
                        'active_addresses_24h': onchain_data.get('active_addresses_24h'),
                        'transaction_count_24h': onchain_data.get('transaction_count_24h'),
                        'exchange_net_flow_24h': onchain_data.get('exchange_net_flow_24h'),
                        'price_volatility_7d': onchain_data.get('price_volatility_7d'),
                        'sma_20': tech_data.get('sma_20'),
                        'rsi_14': tech_data.get('rsi_14'),
                        'macd_line': tech_data.get('macd_line'),
                        'macd_signal': tech_data.get('macd_signal'),
                        'macd_histogram': tech_data.get('macd_histogram'),
                        'bb_upper': tech_data.get('bb_upper'),
                        'bb_middle': tech_data.get('bb_middle'),
                        'bb_lower': tech_data.get('bb_lower'),
                        'vix': macro_data.get('vix'),
                        'spx': None,  # Not available in current macro data
                        'dxy': macro_data.get('dxy'),
                        'treasury_10y': macro_data.get('treasury_10y'),
                        'unemployment_rate': macro_data.get('unemployment_rate'),
                        'inflation_rate': macro_data.get('inflation_rate'),
                        'gold_price': macro_data.get('gold_price'),
                        'oil_price': macro_data.get('oil_price'),
                        'close_price': close_price,
                        'close': close_price
                    }
                    
                    # Insert or update record
                    cursor.execute("""
                        INSERT INTO ml_features_materialized
                        (symbol, price_date, price_hour, timestamp_iso, current_price, price_change_24h, volume_24h, market_cap,
                         avg_ml_overall_sentiment, sentiment_volume,
                         active_addresses_24h, transaction_count_24h, exchange_net_flow_24h, price_volatility_7d,
                         sma_20, rsi_14, macd_line, macd_signal, macd_histogram, bb_upper, bb_middle, bb_lower,
                         vix, spx, dxy, treasury_10y, unemployment_rate, inflation_rate, gold_price, oil_price,
                         close_price, close,
                         created_at, updated_at)
                        VALUES (%(symbol)s, %(price_date)s, %(price_hour)s, %(timestamp_iso)s, %(current_price)s, %(price_change_24h)s, %(volume_24h)s, %(market_cap)s,
                                %(avg_ml_overall_sentiment)s, %(sentiment_volume)s,
                                %(active_addresses_24h)s, %(transaction_count_24h)s, %(exchange_net_flow_24h)s, %(price_volatility_7d)s,
                                %(sma_20)s, %(rsi_14)s, %(macd_line)s, %(macd_signal)s, %(macd_histogram)s, %(bb_upper)s, %(bb_middle)s, %(bb_lower)s,
                                %(vix)s, %(spx)s, %(dxy)s, %(treasury_10y)s, %(unemployment_rate)s, %(inflation_rate)s, %(gold_price)s, %(oil_price)s,
                                %(close_price)s, %(close)s,
                                NOW(), NOW())
                        ON DUPLICATE KEY UPDATE
                        current_price = VALUES(current_price),
                        price_change_24h = VALUES(price_change_24h),
                        volume_24h = VALUES(volume_24h),
                        market_cap = VALUES(market_cap),
                        avg_ml_overall_sentiment = VALUES(avg_ml_overall_sentiment),
                        sentiment_volume = VALUES(sentiment_volume),
                        active_addresses_24h = VALUES(active_addresses_24h),
                        transaction_count_24h = VALUES(transaction_count_24h),
                        exchange_net_flow_24h = VALUES(exchange_net_flow_24h),
                        price_volatility_7d = VALUES(price_volatility_7d),
                        sma_20 = VALUES(sma_20),
                        rsi_14 = VALUES(rsi_14),
                        macd_line = VALUES(macd_line),
                        macd_signal = VALUES(macd_signal),
                        macd_histogram = VALUES(macd_histogram),
                        bb_upper = VALUES(bb_upper),
                        bb_middle = VALUES(bb_middle),
                        bb_lower = VALUES(bb_lower),
                        vix = VALUES(vix),
                        spx = VALUES(spx),
                        dxy = VALUES(dxy),
                        treasury_10y = VALUES(treasury_10y),
                        unemployment_rate = VALUES(unemployment_rate),
                        inflation_rate = VALUES(inflation_rate),
                        gold_price = VALUES(gold_price),
                        oil_price = VALUES(oil_price),
                        close_price = VALUES(close_price),
                        close = VALUES(close),
                        updated_at = NOW()
                    """, insert_data)
                    
                    if cursor.rowcount == 1:
                        inserts += 1
                    else:
                        updates += 1
                        
                except Exception as e:
                    logger.error(f"Error processing {symbol} at {timestamp_iso}: {e}")
                    continue
            
            logger.info(f"Materialized update complete: {inserts} inserted, {updates} updated")
            
        except Exception as e:
            logger.error(f"Error in update_materialized_table: {e}")
        finally:
            if conn:
                conn.close()

    def main():
        """Main function"""
        logger.info("Starting comprehensive materialized updater")
        
        # Initialize connection pool
        init_pool()
        
        # Run continuous updates
        while True:
            try:
                logger.info("Starting materialized table update cycle")
                update_materialized_table()
                logger.info("Materialized table update cycle complete")
                
                # Wait 5 minutes before next update
                time.sleep(300)
                
            except Exception as e:
                logger.error(f"Error in main loop: {e}")
                time.sleep(60)  # Wait 1 minute on error

    if __name__ == "__main__":
        main()
