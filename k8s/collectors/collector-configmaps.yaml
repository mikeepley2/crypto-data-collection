---
# Onchain Collector Code ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
    name: onchain-collector-code
    namespace: crypto-data-collection
    labels:
        app: onchain-collector
data:
    onchain_collector.py: |
        #!/usr/bin/env python3
        """Onchain Data Collector - Collects blockchain metrics for cryptocurrencies"""

        import os
        import logging
        import time
        import json
        import requests
        import mysql.connector
        from datetime import datetime, timedelta
        from dotenv import load_dotenv
        import schedule

        logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        logger = logging.getLogger("onchain-collector")
        load_dotenv()

        def get_db_connection():
            try:
                return mysql.connector.connect(
                    host=os.getenv("DB_HOST", "127.0.0.1"),
                    user=os.getenv("DB_USER", "news_collector"),
                    password=os.getenv("DB_PASSWORD", "99Rules!"),
                    database=os.getenv("DB_NAME", "crypto_prices"),
                )
            except Exception as e:
                logger.error(f"Database connection failed: {e}")
                return None

        def collect_onchain_metrics():
            logger.info("Starting onchain metrics collection...")
            conn = get_db_connection()
            if not conn:
                logger.error("Failed to connect to database")
                return

            try:
                cursor = conn.cursor(dictionary=True)
                cursor.execute("SELECT DISTINCT symbol FROM crypto_assets WHERE is_active = 1 LIMIT 50")
                assets = cursor.fetchall()

                processed = 0
                for asset in assets:
                    symbol = asset["symbol"]
                    try:
                        timestamp = datetime.utcnow()
                        cursor.execute(
                            """INSERT INTO onchain_metrics (
                                coin_symbol, collection_date, timestamp, 
                                active_addresses_24h, transaction_count_24h, 
                                transaction_volume_usd_24h, price_usd, market_cap_usd
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                            ON DUPLICATE KEY UPDATE
                                active_addresses_24h = VALUES(active_addresses_24h),
                                transaction_count_24h = VALUES(transaction_count_24h),
                                transaction_volume_usd_24h = VALUES(transaction_volume_usd_24h),
                                price_usd = VALUES(price_usd),
                                market_cap_usd = VALUES(market_cap_usd)""",
                            (symbol, timestamp, timestamp, None, None, None, None, None),
                        )
                        processed += 1
                    except Exception as e:
                        logger.error(f"Error processing {symbol}: {e}")

                conn.commit()
                logger.info(f"Processed {processed} onchain metrics")
                with open("/tmp/onchain_collector_health.txt", "w") as f:
                    f.write(str(datetime.utcnow()))
            except Exception as e:
                logger.error(f"Error in collection: {e}")
                conn.rollback()
            finally:
                cursor.close()
                conn.close()

        def main():
            logger.info("Onchain Data Collector starting...")
            schedule.every(6).hours.do(collect_onchain_metrics)
            collect_onchain_metrics()
            while True:
                schedule.run_pending()
                time.sleep(60)

        if __name__ == "__main__":
            main()

---
# Macro Collector Code ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
    name: macro-collector-code
    namespace: crypto-data-collection
    labels:
        app: macro-collector
data:
    macro_collector.py: |
        #!/usr/bin/env python3
        """Macro Indicators Collector - Collects macroeconomic indicators"""

        import os
        import logging
        import time
        import mysql.connector
        from datetime import datetime
        import schedule

        logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        logger = logging.getLogger("macro-collector")

        def get_db_connection():
            try:
                return mysql.connector.connect(
                    host=os.getenv("DB_HOST", "127.0.0.1"),
                    user=os.getenv("DB_USER", "news_collector"),
                    password=os.getenv("DB_PASSWORD", "99Rules!"),
                    database=os.getenv("DB_NAME", "crypto_prices"),
                )
            except Exception as e:
                logger.error(f"Database connection failed: {e}")
                return None

        def collect_macro_indicators():
            logger.info("Starting macro indicators collection...")
            conn = get_db_connection()
            if not conn:
                return

            try:
                cursor = conn.cursor()
                indicators = [
                    "US_GDP", "US_INFLATION", "US_UNEMPLOYMENT", "VIX",
                    "GOLD_PRICE", "OIL_PRICE", "DXY", "US_10Y_YIELD",
                ]

                timestamp = datetime.utcnow()
                processed = 0

                for indicator in indicators:
                    try:
                        cursor.execute(
                            """INSERT INTO macro_indicators (
                                indicator_name, indicator_date, value, data_source
                            ) VALUES (%s, %s, %s, %s)
                            ON DUPLICATE KEY UPDATE
                                value = VALUES(value)""",
                            (indicator, timestamp.date(), None, "FRED API"),
                        )
                        processed += 1
                    except Exception as e:
                        logger.error(f"Error for {indicator}: {e}")

                conn.commit()
                logger.info(f"Processed {processed} macro indicators")
                with open("/tmp/macro_collector_health.txt", "w") as f:
                    f.write(str(datetime.utcnow()))
            except Exception as e:
                logger.error(f"Collection error: {e}")
                conn.rollback()
            finally:
                cursor.close()
                conn.close()

        def main():
            logger.info("Macro Indicators Collector starting...")
            schedule.every(1).hours.do(collect_macro_indicators)
            collect_macro_indicators()
            while True:
                schedule.run_pending()
                time.sleep(60)

        if __name__ == "__main__":
            main()

---
# Technical Calculator Code ConfigMap
apiVersion: v1
kind: ConfigMap
metadata:
    name: technical-calculator-code
    namespace: crypto-data-collection
    labels:
        app: technical-calculator
data:
    technical_calculator.py: |
        #!/usr/bin/env python3
        """Technical Indicators Calculator - Calculates technical indicators for price data"""

        import os
        import logging
        import time
        import mysql.connector
        from datetime import datetime, timedelta
        import schedule

        logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s")
        logger = logging.getLogger("technical-calculator")

        def get_db_connection():
            try:
                return mysql.connector.connect(
                    host=os.getenv("DB_HOST", "127.0.0.1"),
                    user=os.getenv("DB_USER", "news_collector"),
                    password=os.getenv("DB_PASSWORD", "99Rules!"),
                    database=os.getenv("DB_NAME", "crypto_prices"),
                )
            except Exception as e:
                logger.error(f"Database connection failed: {e}")
                return None

        def calculate_indicators():
            logger.info("Starting technical indicators calculation...")
            conn = get_db_connection()
            if not conn:
                return

            try:
                cursor = conn.cursor(dictionary=True)

                cursor.execute(
                    """SELECT DISTINCT symbol FROM price_data_real
                       WHERE timestamp > DATE_SUB(NOW(), INTERVAL 30 DAY)
                       ORDER BY symbol LIMIT 50"""
                )

                symbols = cursor.fetchall()
                processed = 0

                for row in symbols:
                    symbol = row["symbol"]
                    try:
                        cursor.execute(
                            """SELECT timestamp, close, high, low, volume
                               FROM price_data_real
                               WHERE symbol = %s
                               ORDER BY timestamp DESC
                               LIMIT 200""",
                            (symbol,),
                        )

                        prices = cursor.fetchall()
                        if not prices:
                            continue

                        close_prices = [float(p["close"]) for p in prices]
                        sma_20 = (sum(close_prices[:20]) / min(20, len(close_prices))) if close_prices else 0
                        sma_50 = (sum(close_prices[:50]) / min(50, len(close_prices))) if close_prices else 0

                        rsi = 50.0
                        macd = 0.0
                        bb_upper = sma_20 * 1.02
                        bb_lower = sma_20 * 0.98
                        timestamp = prices[0]["timestamp"] if prices else datetime.utcnow()

                        cursor.execute(
                            """INSERT INTO technical_indicators (
                                symbol, timestamp, sma_20, sma_50, rsi, macd, bb_upper, bb_lower
                            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
                            ON DUPLICATE KEY UPDATE
                                sma_20 = VALUES(sma_20),
                                sma_50 = VALUES(sma_50),
                                rsi = VALUES(rsi),
                                macd = VALUES(macd),
                                bb_upper = VALUES(bb_upper),
                                bb_lower = VALUES(bb_lower),
                                updated_at = NOW()""",
                            (symbol, timestamp, sma_20, sma_50, rsi, macd, bb_upper, bb_lower),
                        )
                        processed += 1
                    except Exception as e:
                        logger.error(f"Error for {symbol}: {e}")

                conn.commit()
                logger.info(f"Processed {processed} symbols")
                with open("/tmp/technical_calculator_health.txt", "w") as f:
                    f.write(str(datetime.utcnow()))
            except Exception as e:
                logger.error(f"Calculation error: {e}")
                conn.rollback()
            finally:
                cursor.close()
                conn.close()

        def main():
            logger.info("Technical Indicators Calculator starting...")
            schedule.every(5).minutes.do(calculate_indicators)
            calculate_indicators()
            while True:
                schedule.run_pending()
                time.sleep(60)

        if __name__ == "__main__":
            main()
