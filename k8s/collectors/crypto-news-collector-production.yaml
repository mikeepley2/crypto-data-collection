apiVersion: apps/v1
kind: Deployment
metadata:
    name: crypto-news-collector
    namespace: crypto-data-collection
    labels:
        app: crypto-news-collector
        component: data-collector
    annotations:
        prometheus.io/scrape: "true"
        prometheus.io/path: "/metrics"
        prometheus.io/port: "8000"
spec:
    replicas: 1
    selector:
        matchLabels:
            app: crypto-news-collector
    template:
        metadata:
            labels:
                app: crypto-news-collector
                component: data-collector
            annotations:
                prometheus.io/scrape: "true"
                prometheus.io/path: "/metrics"
                prometheus.io/port: "8000"
        spec:
            nodeSelector:
                node-type: data-collection # Target the data collection node
            tolerations:
                - key: "data-platform"
                  operator: "Equal"
                  value: "true"
                  effect: "NoSchedule"
            containers:
                - name: crypto-news-collector
                  image: python:3.11-slim
                  command: ["/bin/bash", "-c"]
                  args:
                      - |
                          # Install dependencies
                          pip install fastapi uvicorn feedparser requests tenacity prometheus-client circuitbreaker redis mysql-connector-python

                          # Create app directory
                          mkdir -p /app

                          # Create the production crypto news collector service
                          cat > /app/crypto_news_collector.py << 'EOF'
                          import os
                          import sys
                          import json
                          import time
                          import hashlib
                          import logging
                          import asyncio
                          from datetime import datetime, timedelta
                          from typing import List, Dict, Optional, Set
                          from dataclasses import dataclass

                          import feedparser
                          import requests
                          from requests.adapters import HTTPAdapter
                          from urllib3.util.retry import Retry
                          from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
                          from circuitbreaker import CircuitBreaker
                          from prometheus_client import Counter, Histogram, Gauge, generate_latest, CONTENT_TYPE_LATEST
                          import mysql.connector
                          import redis
                          from fastapi import FastAPI, BackgroundTasks, HTTPException
                          from fastapi.responses import Response, JSONResponse
                          import uvicorn

                          # Set up structured logging
                          logging.basicConfig(
                              level=logging.INFO,
                              format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                          )
                          logger = logging.getLogger(__name__)

                          # Prometheus metrics
                          NEWS_COLLECTION_REQUESTS = Counter(
                              'news_collection_requests_total',
                              'Total news collection requests',
                              ['source', 'status']
                          )

                          NEWS_COLLECTION_DURATION = Histogram(
                              'news_collection_duration_seconds',
                              'News collection duration',
                              ['source']
                          )

                          NEWS_COLLECTION_ERRORS = Counter(
                              'news_collection_errors_total',
                              'Total news collection errors',
                              ['source', 'error_type']
                          )

                          NEWS_ITEMS_STORED = Counter(
                              'news_items_stored_total',
                              'Total news items stored',
                              ['source']
                          )

                          NEWS_SOURCES_ACTIVE = Gauge(
                              'news_sources_active',
                              'Number of active news sources'
                          )

                          CIRCUIT_BREAKER_STATE = Gauge(
                              'circuit_breaker_state',
                              'Circuit breaker state (0=closed, 1=open, 2=half-open)',
                              ['source']
                          )

                          @dataclass
                          class NewsItem:
                              title: str
                              content: str
                              url: str
                              published_at: datetime
                              source: str
                              category: str
                              sentiment_score: float
                              crypto_mentions: List[str]
                              url_hash: str

                          class NewsCollector:
                              def __init__(self):
                                  self.app = FastAPI(
                                      title="Crypto News Collector",
                                      description="Production-grade cryptocurrency news collection service",
                                      version="2.0.0"
                                  )
                                  self.setup_routes()
                                  
                                  # News sources configuration - Expanded for comprehensive coverage
                                  self.rss_sources = [
                                      # Major Crypto Publications
                                      {
                                          "name": "CoinDesk",
                                          "url": "https://www.coindesk.com/arc/outboundfeeds/rss/",
                                          "category": "general"
                                      },
                                      {
                                          "name": "CoinTelegraph", 
                                          "url": "https://cointelegraph.com/rss",
                                          "category": "general"
                                      },
                                      {
                                          "name": "CryptoSlate",
                                          "url": "https://cryptoslate.com/feed/",
                                          "category": "general"
                                      },
                                      {
                                          "name": "Decrypt",
                                          "url": "https://decrypt.co/feed",
                                          "category": "general"
                                      },
                                      {
                                          "name": "Bitcoin Magazine",
                                          "url": "https://bitcoinmagazine.com/feed",
                                          "category": "bitcoin"
                                      },
                                      {
                                          "name": "CoinJournal",
                                          "url": "https://coinjournal.net/feed/",
                                          "category": "general"
                                      },
                                      {
                                          "name": "NewsBTC",
                                          "url": "https://www.newsbtc.com/feed/",
                                          "category": "general"
                                      },
                                      {
                                          "name": "BeInCrypto",
                                          "url": "https://beincrypto.com/feed/",
                                          "category": "general"
                                      },
                                      
                                      # DeFi and Technical Focus
                                      {
                                          "name": "The Block",
                                          "url": "https://www.theblock.co/rss.xml",
                                          "category": "defi"
                                      },
                                      {
                                          "name": "DeFi Pulse",
                                          "url": "https://defipulse.com/blog/feed/",
                                          "category": "defi"
                                      },
                                      {
                                          "name": "CoinGecko",
                                          "url": "https://www.coingecko.com/en/news/feed",
                                          "category": "market"
                                      },
                                      {
                                          "name": "CoinMarketCap",
                                          "url": "https://coinmarketcap.com/headlines/news/feed/",
                                          "category": "market"
                                      },
                                      
                                      # Regulatory and Institutional
                                      {
                                          "name": "Coin Center",
                                          "url": "https://www.coincenter.org/feed/",
                                          "category": "regulatory"
                                      },
                                      {
                                          "name": "Blockchain Association",
                                          "url": "https://theblockchainassociation.org/feed/",
                                          "category": "regulatory"
                                      },
                                      
                                      # Technical and Development
                                      {
                                          "name": "Ethereum Foundation",
                                          "url": "https://blog.ethereum.org/feed.xml",
                                          "category": "ethereum"
                                      },
                                      {
                                          "name": "Bitcoin Core",
                                          "url": "https://bitcoin.org/en/rss.xml",
                                          "category": "bitcoin"
                                      },
                                      {
                                          "name": "Solana",
                                          "url": "https://solana.com/news/rss.xml",
                                          "category": "solana"
                                      },
                                      {
                                          "name": "Polygon",
                                          "url": "https://blog.polygon.technology/feed/",
                                          "category": "ethereum"
                                      },
                                      
                                      # Trading and Analysis
                                      {
                                          "name": "Crypto Briefing",
                                          "url": "https://cryptobriefing.com/feed/",
                                          "category": "analysis"
                                      },
                                      {
                                          "name": "Crypto Daily",
                                          "url": "https://cryptodaily.co.uk/feed",
                                          "category": "general"
                                      },
                                      {
                                          "name": "AMBCrypto",
                                          "url": "https://ambcrypto.com/feed/",
                                          "category": "analysis"
                                      },
                                      {
                                          "name": "Crypto News",
                                          "url": "https://cryptonews.com/news/feed/",
                                          "category": "general"
                                      },
                                      
                                      # International Coverage
                                      {
                                          "name": "CoinSpeaker",
                                          "url": "https://www.coinspeaker.com/feed/",
                                          "category": "international"
                                      },
                                      {
                                          "name": "CryptoGlobe",
                                          "url": "https://www.cryptoglobe.com/latest/feed/",
                                          "category": "international"
                                      },
                                      {
                                          "name": "Bitcoinist",
                                          "url": "https://bitcoinist.com/feed/",
                                          "category": "bitcoin"
                                      },
                                      {
                                          "name": "Crypto News Flash",
                                          "url": "https://www.crypto-news-flash.com/feed/",
                                          "category": "general"
                                      }
                                  ]
                                  
                                  # API sources (free tier)
                                  self.api_sources = [
                                      {
                                          "name": "CryptoPanic",
                                          "url": "https://cryptopanic.com/api/v1/posts/",
                                          "params": {"auth_token": "", "public": "true", "filter": "hot"},
                                          "category": "aggregated"
                                      }
                                  ]
                                  
                                  # Circuit breakers for each source
                                  self.circuit_breakers = {}
                                  for source in self.rss_sources + self.api_sources:
                                      self.circuit_breakers[source["name"]] = CircuitBreaker(
                                          failure_threshold=5,
                                          recovery_timeout=60,
                                          expected_exception=Exception
                                      )
                                  
                                  # HTTP session with retry strategy
                                  self.session = requests.Session()
                                  retry_strategy = Retry(
                                      total=3,
                                      backoff_factor=1,
                                      status_forcelist=[429, 500, 502, 503, 504],
                                  )
                                  adapter = HTTPAdapter(max_retries=retry_strategy)
                                  self.session.mount("http://", adapter)
                                  self.session.mount("https://", adapter)
                                  
                                  # Redis connection for caching
                                  try:
                                      self.redis_client = redis.Redis(
                                          host=os.getenv("REDIS_HOST", "redis-data-collection.crypto-data-collection.svc.cluster.local"),
                                          port=int(os.getenv("REDIS_PORT", "6379")),
                                          decode_responses=True
                                      )
                                      self.redis_client.ping()
                                      logger.info("âœ… Connected to Redis for caching")
                                  except Exception as e:
                                      logger.warning(f"âš ï¸ Redis connection failed: {e}")
                                      self.redis_client = None
                                  
                                  # Stats
                                  self.stats = {
                                      "total_collected": 0,
                                      "total_stored": 0,
                                      "last_collection": None,
                                      "collection_errors": 0,
                                      "sources_active": len(self.rss_sources) + len(self.api_sources),
                                      "duplicates_filtered": 0
                                  }
                                  
                                  # Update metrics
                                  NEWS_SOURCES_ACTIVE.set(self.stats["sources_active"])
                              
                              def get_db_connection(self):
                                  """Get database connection"""
                                  try:
                                      config = {
                                          "host": os.getenv("MYSQL_HOST", "host.docker.internal"),
                                          "user": os.getenv("MYSQL_USER", "news_collector"),
                                          "password": os.getenv("MYSQL_PASSWORD", "99Rules!"),
                                          "database": os.getenv("MYSQL_DATABASE", "crypto_prices"),
                                          "charset": "utf8mb4",
                                          "autocommit": False
                                      }
                                      return mysql.connector.connect(**config)
                                  except Exception as e:
                                      logger.error(f"Database connection error: {e}")
                                      return None
                              
                              def extract_crypto_mentions(self, text: str) -> List[str]:
                                  """Extract cryptocurrency mentions from text"""
                                  crypto_symbols = [
                                      "BTC", "ETH", "BNB", "ADA", "SOL", "XRP", "DOT", "DOGE", "AVAX", "SHIB",
                                      "MATIC", "LTC", "UNI", "LINK", "ATOM", "XLM", "BCH", "ALGO", "VET", "ICP",
                                      "FIL", "TRX", "ETC", "XMR", "EOS", "AAVE", "SUSHI", "COMP", "MKR", "YFI"
                                  ]
                                  
                                  mentions = []
                                  text_upper = text.upper()
                                  for symbol in crypto_symbols:
                                      if symbol in text_upper:
                                          mentions.append(symbol)
                                  
                                  return list(set(mentions))
                              
                              def create_url_hash(self, url: str) -> str:
                                  """Create hash for URL deduplication"""
                                  return hashlib.md5(url.encode()).hexdigest()
                              
                              def is_duplicate(self, url_hash: str) -> bool:
                                  """Check if news item is duplicate using Redis cache"""
                                  if not self.redis_client:
                                      return False
                                  
                                  try:
                                      return self.redis_client.exists(f"news_hash:{url_hash}")
                                  except Exception as e:
                                      logger.warning(f"Redis duplicate check failed: {e}")
                                      return False
                              
                              def mark_as_processed(self, url_hash: str, ttl_hours: int = 24):
                                  """Mark news item as processed in Redis"""
                                  if not self.redis_client:
                                      return
                                  
                                  try:
                                      self.redis_client.setex(f"news_hash:{url_hash}", ttl_hours * 3600, "1")
                                  except Exception as e:
                                      logger.warning(f"Redis mark processed failed: {e}")
                              
                              @retry(
                                  stop=stop_after_attempt(3),
                                  wait=wait_exponential(multiplier=1, min=2, max=8),
                                  retry=retry_if_exception_type((requests.RequestException,))
                              )
                              def collect_rss_news(self, source: Dict) -> List[NewsItem]:
                                  """Collect news from RSS feed"""
                                  circuit_breaker = self.circuit_breakers[source["name"]]
                                  
                                  @circuit_breaker
                                  def _collect():
                                      logger.info(f"Collecting RSS news from {source['name']}")
                                      
                                      response = self.session.get(source["url"], timeout=30)
                                      response.raise_for_status()
                                      
                                      feed = feedparser.parse(response.content)
                                      news_items = []
                                      
                                      for entry in feed.entries[:20]:  # Limit to 20 most recent
                                          try:
                                              # Parse published date
                                              if hasattr(entry, 'published_parsed') and entry.published_parsed:
                                                  published_at = datetime(*entry.published_parsed[:6])
                                              else:
                                                  published_at = datetime.now()
                                              
                                              # Create URL hash for deduplication
                                              url_hash = self.create_url_hash(entry.link)
                                              
                                              # Check for duplicates
                                              if self.is_duplicate(url_hash):
                                                  self.stats["duplicates_filtered"] += 1
                                                  continue
                                              
                                              # Extract content
                                              content = ""
                                              if hasattr(entry, 'summary'):
                                                  content = entry.summary
                                              elif hasattr(entry, 'description'):
                                                  content = entry.description
                                              
                                              # Extract crypto mentions
                                              crypto_mentions = self.extract_crypto_mentions(
                                                  f"{entry.title} {content}"
                                              )
                                              
                                              news_item = NewsItem(
                                                  title=entry.title,
                                                  content=content,
                                                  url=entry.link,
                                                  published_at=published_at,
                                                  source=source["name"],
                                                  category=source["category"],
                                                  sentiment_score=0.0,  # Will be calculated by sentiment service
                                                  crypto_mentions=crypto_mentions,
                                                  url_hash=url_hash
                                              )
                                              
                                              news_items.append(news_item)
                                              self.mark_as_processed(url_hash)
                                              
                                          except Exception as e:
                                              logger.error(f"Error parsing RSS entry from {source['name']}: {e}")
                                              continue
                                      
                                      logger.info(f"Collected {len(news_items)} news items from {source['name']}")
                                      return news_items
                                  
                                  try:
                                      return _collect()
                                  except Exception as e:
                                      logger.error(f"Circuit breaker open for {source['name']}: {e}")
                                      CIRCUIT_BREAKER_STATE.labels(source=source["name"]).set(1)  # Open
                                      NEWS_COLLECTION_ERRORS.labels(source=source["name"], error_type="circuit_breaker").inc()
                                      return []
                              
                              @retry(
                                  stop=stop_after_attempt(3),
                                  wait=wait_exponential(multiplier=1, min=2, max=8),
                                  retry=retry_if_exception_type((requests.RequestException,))
                              )
                              def collect_api_news(self, source: Dict) -> List[NewsItem]:
                                  """Collect news from API source"""
                                  circuit_breaker = self.circuit_breakers[source["name"]]
                                  
                                  @circuit_breaker
                                  def _collect():
                                      logger.info(f"Collecting API news from {source['name']}")
                                      
                                      response = self.session.get(source["url"], params=source["params"], timeout=30)
                                      response.raise_for_status()
                                      
                                      data = response.json()
                                      news_items = []
                                      
                                      if source["name"] == "CryptoPanic":
                                          for post in data.get("results", [])[:20]:  # Limit to 20
                                              try:
                                                  # Parse published date
                                                  published_at = datetime.fromisoformat(
                                                      post["published_at"].replace("Z", "+00:00")
                                                  )
                                                  
                                                  # Create URL hash
                                                  url_hash = self.create_url_hash(post["url"])
                                                  
                                                  # Check for duplicates
                                                  if self.is_duplicate(url_hash):
                                                      self.stats["duplicates_filtered"] += 1
                                                      continue
                                                  
                                                  # Extract crypto mentions
                                                  crypto_mentions = self.extract_crypto_mentions(
                                                      f"{post['title']} {post.get('body', '')}"
                                                  )
                                                  
                                                  news_item = NewsItem(
                                                      title=post["title"],
                                                      content=post.get("body", ""),
                                                      url=post["url"],
                                                      published_at=published_at,
                                                      source=source["name"],
                                                      category=source["category"],
                                                      sentiment_score=0.0,
                                                      crypto_mentions=crypto_mentions,
                                                      url_hash=url_hash
                                                  )
                                                  
                                                  news_items.append(news_item)
                                                  self.mark_as_processed(url_hash)
                                                  
                                              except Exception as e:
                                                  logger.error(f"Error parsing API entry from {source['name']}: {e}")
                                                  continue
                                      
                                      logger.info(f"Collected {len(news_items)} news items from {source['name']}")
                                      return news_items
                                  
                                  try:
                                      return _collect()
                                  except Exception as e:
                                      logger.error(f"Circuit breaker open for {source['name']}: {e}")
                                      CIRCUIT_BREAKER_STATE.labels(source=source["name"]).set(1)  # Open
                                      NEWS_COLLECTION_ERRORS.labels(source=source["name"], error_type="circuit_breaker").inc()
                                      return []
                              
                              def store_news_items(self, news_items: List[NewsItem]) -> int:
                                  """Store news items in database"""
                                  if not news_items:
                                      return 0
                                  
                                  conn = self.get_db_connection()
                                  if not conn:
                                      logger.error("No database connection available")
                                      return 0
                                  
                                  cursor = conn.cursor()
                                  stored_count = 0
                                  
                                  try:
                                      for item in news_items:
                                          try:
                                              insert_sql = """
                                              INSERT INTO crypto_news (
                                                  title, content, url, published_at, source, 
                                                  category, sentiment_score, sentiment_confidence,
                                                  llm_sentiment_score, llm_sentiment_confidence, llm_sentiment_analysis,
                                                  market_type, stock_sentiment_score, stock_sentiment_confidence, stock_sentiment_analysis,
                                                  crypto_mentions, url_hash, created_at, updated_at
                                              ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                                              ON DUPLICATE KEY UPDATE
                                                  content = VALUES(content),
                                                  sentiment_score = VALUES(sentiment_score),
                                                  sentiment_confidence = VALUES(sentiment_confidence),
                                                  updated_at = NOW()
                                              """
                                              
                                              cursor.execute(insert_sql, (
                                                  item.title,
                                                  item.content,
                                                  item.url,
                                                  item.published_at,
                                                  item.source,
                                                  item.category,
                                                  item.sentiment_score,
                                                  getattr(item, 'sentiment_confidence', None),
                                                  None,  # llm_sentiment_score
                                                  None,  # llm_sentiment_confidence
                                                  None,  # llm_sentiment_analysis
                                                  'crypto',  # market_type
                                                  None,  # stock_sentiment_score
                                                  None,  # stock_sentiment_confidence
                                                  None,  # stock_sentiment_analysis
                                                  ",".join(item.crypto_mentions),
                                                  item.url_hash
                                              ))
                                              
                                              stored_count += 1
                                              NEWS_ITEMS_STORED.labels(source=item.source).inc()
                                              
                                          except Exception as e:
                                              logger.error(f"Error storing news item: {e}")
                                              continue
                                      
                                      conn.commit()
                                      logger.info(f"Stored {stored_count} news items in database")
                                      
                                  except Exception as e:
                                      logger.error(f"Database transaction error: {e}")
                                      conn.rollback()
                                  finally:
                                      cursor.close()
                                      conn.close()
                                  
                                  return stored_count
                              
                              def run_collection_cycle(self) -> Dict:
                                  """Run one complete news collection cycle"""
                                  logger.info("Starting news collection cycle...")
                                  start_time = time.time()
                                  
                                  total_collected = 0
                                  total_stored = 0
                                  
                                  # Collect from RSS sources
                                  for source in self.rss_sources:
                                      try:
                                          with NEWS_COLLECTION_DURATION.labels(source=source["name"]).time():
                                              news_items = self.collect_rss_news(source)
                                              
                                          if news_items:
                                              stored = self.store_news_items(news_items)
                                              total_collected += len(news_items)
                                              total_stored += stored
                                              NEWS_COLLECTION_REQUESTS.labels(source=source["name"], status="success").inc()
                                          else:
                                              NEWS_COLLECTION_REQUESTS.labels(source=source["name"], status="empty").inc()
                                          
                                          # Small delay between sources
                                          time.sleep(1)
                                          
                                      except Exception as e:
                                          logger.error(f"Error processing RSS source {source['name']}: {e}")
                                          NEWS_COLLECTION_ERRORS.labels(source=source["name"], error_type="collection").inc()
                                          NEWS_COLLECTION_REQUESTS.labels(source=source["name"], status="error").inc()
                                          continue
                                  
                                  # Collect from API sources
                                  for source in self.api_sources:
                                      try:
                                          with NEWS_COLLECTION_DURATION.labels(source=source["name"]).time():
                                              news_items = self.collect_api_news(source)
                                              
                                          if news_items:
                                              stored = self.store_news_items(news_items)
                                              total_collected += len(news_items)
                                              total_stored += stored
                                              NEWS_COLLECTION_REQUESTS.labels(source=source["name"], status="success").inc()
                                          else:
                                              NEWS_COLLECTION_REQUESTS.labels(source=source["name"], status="empty").inc()
                                          
                                          # Delay between API calls
                                          time.sleep(2)
                                          
                                      except Exception as e:
                                          logger.error(f"Error processing API source {source['name']}: {e}")
                                          NEWS_COLLECTION_ERRORS.labels(source=source["name"], error_type="collection").inc()
                                          NEWS_COLLECTION_REQUESTS.labels(source=source["name"], status="error").inc()
                                          continue
                                  
                                  duration = time.time() - start_time
                                  
                                  # Update stats
                                  self.stats["total_collected"] += total_collected
                                  self.stats["total_stored"] += total_stored
                                  self.stats["last_collection"] = datetime.now()
                                  
                                  result = {
                                      "status": "completed",
                                      "duration_seconds": duration,
                                      "items_collected": total_collected,
                                      "items_stored": total_stored,
                                      "sources_processed": len(self.rss_sources) + len(self.api_sources),
                                      "duplicates_filtered": self.stats["duplicates_filtered"],
                                      "errors": self.stats["collection_errors"]
                                  }
                                  
                                  logger.info(f"Collection cycle completed: {result}")
                                  return result
                              
                              def setup_routes(self):
                                  """Setup FastAPI routes"""
                                  
                                  @self.app.get("/health")
                                  def health():
                                      """Health check endpoint"""
                                      try:
                                          # Check database connection
                                          conn = self.get_db_connection()
                                          db_status = "healthy" if conn else "unhealthy"
                                          if conn:
                                              conn.close()
                                          
                                          # Check Redis connection
                                          redis_status = "healthy"
                                          if self.redis_client:
                                              try:
                                                  self.redis_client.ping()
                                              except:
                                                  redis_status = "unhealthy"
                                          else:
                                              redis_status = "disabled"
                                          
                                          return {
                                              "status": "healthy" if db_status == "healthy" else "unhealthy",
                                              "service": "crypto-news-collector",
                                              "database": db_status,
                                              "redis": redis_status,
                                              "last_collection": self.stats["last_collection"],
                                              "sources_active": self.stats["sources_active"]
                                          }
                                      except Exception as e:
                                          return {
                                              "status": "unhealthy",
                                              "error": str(e)
                                          }
                                  
                                  @self.app.get("/status")
                                  def status():
                                      """Status endpoint with detailed information"""
                                      return {
                                          "service": "crypto-news-collector",
                                          "version": "2.0.0",
                                          "stats": self.stats,
                                          "sources": {
                                              "rss": len(self.rss_sources),
                                              "api": len(self.api_sources),
                                              "total": len(self.rss_sources) + len(self.api_sources)
                                          },
                                          "circuit_breakers": {
                                              name: "open" if cb.failure_count >= 5 else "closed"
                                              for name, cb in self.circuit_breakers.items()
                                          }
                                      }
                                  
                                  @self.app.post("/collect")
                                  def collect_news(background_tasks: BackgroundTasks):
                                      """Trigger news collection"""
                                      background_tasks.add_task(self.run_collection_cycle)
                                      return {
                                          "status": "started",
                                          "message": "News collection initiated",
                                          "sources": len(self.rss_sources) + len(self.api_sources)
                                      }
                                  
                                  @self.app.get("/metrics")
                                  def metrics():
                                      """Prometheus metrics endpoint"""
                                      return Response(
                                          generate_latest(),
                                          media_type=CONTENT_TYPE_LATEST
                                      )

                          # Create the service instance
                          news_collector = NewsCollector()
                          app = news_collector.app

                          if __name__ == "__main__":
                              logger.info("ðŸš€ Starting Production Crypto News Collector Service v2.0.0")
                              uvicorn.run(app, host="0.0.0.0", port=8000)
                          EOF

                          # Start the service
                          cd /app && python crypto_news_collector.py
                  ports:
                      - containerPort: 8000
                        name: http
                  env:
                      - name: MYSQL_HOST
                        valueFrom:
                            configMapKeyRef:
                                name: centralized-db-config
                                key: MYSQL_HOST
                      - name: MYSQL_PORT
                        valueFrom:
                            configMapKeyRef:
                                name: centralized-db-config
                                key: MYSQL_PORT
                      - name: MYSQL_USER
                        valueFrom:
                            secretKeyRef:
                                name: centralized-db-secrets
                                key: mysql-user
                      - name: MYSQL_PASSWORD
                        valueFrom:
                            secretKeyRef:
                                name: centralized-db-secrets
                                key: mysql-password
                      - name: MYSQL_DATABASE
                        valueFrom:
                            configMapKeyRef:
                                name: centralized-db-config
                                key: MYSQL_DATABASE
                      - name: REDIS_HOST
                        valueFrom:
                            configMapKeyRef:
                                name: centralized-db-config
                                key: REDIS_HOST
                      - name: REDIS_PORT
                        valueFrom:
                            configMapKeyRef:
                                name: centralized-db-config
                                key: REDIS_PORT
                  resources:
                      requests:
                          cpu: 300m
                          memory: 512Mi
                      limits:
                          cpu: 1000m
                          memory: 1Gi
                  livenessProbe:
                      httpGet:
                          path: /health
                          port: 8000
                      initialDelaySeconds: 30
                      periodSeconds: 30
                      timeoutSeconds: 10
                      failureThreshold: 3
                  readinessProbe:
                      httpGet:
                          path: /health
                          port: 8000
                      initialDelaySeconds: 10
                      periodSeconds: 10
                      timeoutSeconds: 5
                      failureThreshold: 3
---
apiVersion: v1
kind: Service
metadata:
    name: crypto-news-collector
    namespace: crypto-data-collection
    labels:
        app: crypto-news-collector
        component: data-collector
spec:
    selector:
        app: crypto-news-collector
    ports:
        - protocol: TCP
          port: 8000
          targetPort: 8000
    type: ClusterIP
