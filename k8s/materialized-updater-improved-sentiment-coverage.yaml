apiVersion: apps/v1
kind: Deployment
metadata:
  name: materialized-updater
  namespace: crypto-data-collection
  labels:
    app: materialized-updater
    component: data-collector
spec:
  replicas: 1
  selector:
    matchLabels:
      app: materialized-updater
  template:
    metadata:
      labels:
        app: materialized-updater
        component: data-collector
    spec:
      containers:
        - name: materialized-updater
          image: python:3.11-slim
          command: ["/bin/bash", "-c"]
          args:
            - |
              pip install fastapi uvicorn mysql-connector-python requests

              # Create the materialized updater service with IMPROVED sentiment coverage
              cat > materialized_updater.py << 'EOF'
              import mysql.connector
              import logging
              import time
              import os
              from datetime import datetime, timedelta
              from fastapi import FastAPI
              from fastapi.responses import JSONResponse
              import uvicorn

              # Set up logging
              logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
              logger = logging.getLogger(__name__)

              app = FastAPI(title="Materialized Updater", version="1.0.0")

              def get_db_connection():
                  """Get database connection using environment variables"""
                  config = {
                      "host": os.getenv("MYSQL_HOST", "host.docker.internal"),
                      "user": os.getenv("MYSQL_USER", "news_collector"),
                      "password": os.getenv("MYSQL_PASSWORD", "99Rules!"),
                      "database": os.getenv("MYSQL_DATABASE", "crypto_prices"),
                      "charset": "utf8mb4"
                  }
                  return mysql.connector.connect(**config)

              def load_symbols_from_db():
                  """Load all active coin symbols from the crypto_assets table."""
                  symbols = []
                  try:
                      conn = get_db_connection()
                      cursor = conn.cursor(dictionary=True)
                      cursor.execute("SELECT symbol FROM crypto_assets WHERE is_active=1")
                      symbols = [row['symbol'] for row in cursor.fetchall()]
                      cursor.close()
                      conn.close()
                      logger.info(f"‚úÖ Loaded {len(symbols)} symbols from crypto_assets table.")
                  except Exception as e:
                      logger.error(f"‚ùå Error loading symbols from crypto_assets: {e}")
                  return symbols

              def update_materialized_table():
                  """Update the materialized table with recent price data, sentiment aggregation, and onchain data"""
                  try:
                      conn = get_db_connection()
                      cursor = conn.cursor()
                      
                      # Get recent price data (last 1 hour for balanced updates)
                      cursor.execute('''
                      SELECT symbol, timestamp_iso, current_price, price_change_24h, volume_usd_24h, market_cap 
                      FROM price_data_real 
                      WHERE timestamp_iso > DATE_SUB(NOW(), INTERVAL 1 HOUR) 
                      ORDER BY timestamp_iso DESC
                      LIMIT 3000
                      ''')
                      recent_data = cursor.fetchall()
                      
                      inserted_count = 0
                      skipped_count = 0
                      
                      for row in recent_data:
                          symbol, timestamp_iso, current_price, price_change_24h, volume_24h, market_cap = row
                          
                          try:
                              # Extract date and hour from timestamp
                              price_date = timestamp_iso.date()
                              price_hour = timestamp_iso.hour
                              
                              # Get sentiment data for this symbol and time period (last 24 hours)
                              # IMPROVED: Try symbol-specific sentiment first, then fall back to general sentiment
                              cursor.execute('''
                              SELECT 
                                  AVG(CASE WHEN market_type = 'crypto' THEN ml_sentiment_score ELSE NULL END) as avg_crypto_sentiment,
                                  AVG(CASE WHEN market_type = 'stock' THEN ml_sentiment_score ELSE NULL END) as avg_stock_sentiment,
                                  AVG(CASE WHEN market_type = 'social' THEN ml_sentiment_score ELSE NULL END) as avg_social_sentiment,
                                  AVG(ml_sentiment_score) as avg_overall_sentiment,
                                  COUNT(*) as sentiment_count
                              FROM crypto_news 
                              WHERE published_at >= DATE_SUB(%s, INTERVAL 24 HOUR)
                              AND (crypto_mentions LIKE %s OR title LIKE %s OR content LIKE %s)
                              AND ml_sentiment_score IS NOT NULL
                              ''', (timestamp_iso, f'%{symbol}%', f'%{symbol}%', f'%{symbol}%'))
                              
                              sentiment_data = cursor.fetchone()
                              avg_crypto_sentiment, avg_stock_sentiment, avg_social_sentiment, avg_overall_sentiment, sentiment_count = sentiment_data
                              
                              # If no symbol-specific sentiment, use general crypto sentiment
                              if sentiment_count == 0 or avg_overall_sentiment is None:
                                  cursor.execute('''
                                  SELECT 
                                      AVG(ml_sentiment_score) as avg_general_crypto_sentiment,
                                      COUNT(*) as general_sentiment_count
                                  FROM crypto_news 
                                  WHERE published_at >= DATE_SUB(%s, INTERVAL 24 HOUR)
                                  AND market_type = 'crypto'
                                  AND ml_sentiment_score IS NOT NULL
                                  ''', (timestamp_iso,))
                                  
                                  general_sentiment_data = cursor.fetchone()
                                  if general_sentiment_data and general_sentiment_data[0] is not None:
                                      avg_crypto_sentiment = general_sentiment_data[0]
                                      avg_overall_sentiment = general_sentiment_data[0]
                                      sentiment_count = general_sentiment_data[1]
                                      logger.info(f"Using general sentiment for {symbol}: {avg_overall_sentiment:.3f}")
                              
                              # Get general stock sentiment (not symbol-specific)
                              cursor.execute('''
                              SELECT 
                                  AVG(ml_sentiment_score) as avg_general_stock_sentiment,
                                  COUNT(*) as stock_sentiment_count
                              FROM crypto_news 
                              WHERE published_at >= DATE_SUB(%s, INTERVAL 24 HOUR)
                              AND market_type = 'stock'
                              AND ml_sentiment_score IS NOT NULL
                              ''', (timestamp_iso,))
                              
                              general_stock_data = cursor.fetchone()
                              if general_stock_data and general_stock_data[0] is not None:
                                  avg_stock_sentiment = general_stock_data[0]
                                  stock_sentiment_count = general_stock_data[1]
                              else:
                                  stock_sentiment_count = 0
                              
                              # Get onchain data for this symbol and time period (last 24 hours)
                              cursor.execute('''
                              SELECT 
                                  active_addresses_24h,
                                  transaction_count_24h,
                                  exchange_net_flow_24h,
                                  price_volatility_7d
                              FROM crypto_onchain_data 
                              WHERE coin_symbol COLLATE utf8mb4_unicode_ci = %s 
                              AND collection_date >= DATE_SUB(%s, INTERVAL 24 HOUR)
                              AND active_addresses_24h IS NOT NULL
                              AND transaction_count_24h IS NOT NULL
                              ORDER BY collection_date DESC
                              LIMIT 1
                              ''', (symbol, timestamp_iso))
                              
                              onchain_data = cursor.fetchone()
                              if onchain_data:
                                  active_addresses_24h, transaction_count_24h, exchange_net_flow_24h, price_volatility_7d = onchain_data
                              else:
                                  active_addresses_24h, transaction_count_24h, exchange_net_flow_24h, price_volatility_7d = None, None, None, None
                              
                              # Use INSERT ... ON DUPLICATE KEY UPDATE to handle existing records
                              insert_query = '''
                              INSERT INTO ml_features_materialized 
                              (symbol, price_date, price_hour, timestamp_iso, current_price, price_change_24h, volume_24h, market_cap, 
                               avg_ml_crypto_sentiment, avg_ml_stock_sentiment, avg_ml_social_sentiment, avg_ml_overall_sentiment, sentiment_volume,
                               active_addresses_24h, transaction_count_24h, exchange_net_flow_24h, price_volatility_7d,
                               created_at, updated_at)
                              VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), NOW())
                              ON DUPLICATE KEY UPDATE
                              current_price = VALUES(current_price),
                              price_change_24h = VALUES(price_change_24h),
                              volume_24h = VALUES(volume_24h),
                              market_cap = VALUES(market_cap),
                              avg_ml_crypto_sentiment = VALUES(avg_ml_crypto_sentiment),
                              avg_ml_stock_sentiment = VALUES(avg_ml_stock_sentiment),
                              avg_ml_social_sentiment = VALUES(avg_ml_social_sentiment),
                              avg_ml_overall_sentiment = VALUES(avg_ml_overall_sentiment),
                              sentiment_volume = VALUES(sentiment_volume),
                              active_addresses_24h = VALUES(active_addresses_24h),
                              transaction_count_24h = VALUES(transaction_count_24h),
                              exchange_net_flow_24h = VALUES(exchange_net_flow_24h),
                              price_volatility_7d = VALUES(price_volatility_7d),
                              updated_at = NOW()
                              '''
                              cursor.execute(insert_query, (symbol, price_date, price_hour, timestamp_iso, current_price, price_change_24h, volume_24h, market_cap,
                                                           avg_crypto_sentiment, avg_stock_sentiment, avg_social_sentiment, avg_overall_sentiment, sentiment_count,
                                                          active_addresses_24h, transaction_count_24h, exchange_net_flow_24h, price_volatility_7d))
                              inserted_count += 1
                          except Exception as e:
                              logger.error(f'Error inserting {symbol}: {e}')
                              skipped_count += 1
                      
                      conn.commit()
                      cursor.close()
                      conn.close()
                      
                      logger.info(f"‚úÖ Updated materialized table with {inserted_count} new records, skipped {skipped_count} existing")
                      return inserted_count
                      
                  except Exception as e:
                      logger.error(f"‚ùå Error updating materialized table: {e}")
                      return 0

              @app.get("/health")
              def health_check():
                  return {"status": "healthy", "service": "materialized-updater"}

              @app.post("/update")
              def update_materialized():
                  try:
                      count = update_materialized_table()
                      return {"status": "success", "records_updated": count}
                  except Exception as e:
                      logger.error(f"Update error: {e}")
                      return {"status": "error", "message": str(e)}

              @app.get("/symbols")
              def get_symbols():
                  symbols = load_symbols_from_db()
                  return {"symbols": symbols, "count": len(symbols)}

              @app.get("/")
              def root():
                  return {"message": "Materialized Updater Service", "status": "running"}

              import threading
              import asyncio

              def background_update_loop():
                  """Background loop to automatically update materialized table"""
                  while True:
                      try:
                          logger.info("üîÑ Starting automatic materialized table update...")
                          count = update_materialized_table()
                          logger.info(f"‚úÖ Automatic update completed: {count} records updated")
                      except Exception as e:
                          logger.error(f"‚ùå Error in background update: {e}")
                      
                      # Wait 5 minutes before next update (balanced frequency for database size management)
                      time.sleep(300)

              if __name__ == "__main__":
                  logger.info("üöÄ Starting Materialized Updater Service with Automatic Updates")
                  
                  # Start background update thread
                  update_thread = threading.Thread(target=background_update_loop, daemon=True)
                  update_thread.start()
                  
                  # Start the web service
                  uvicorn.run(app, host="0.0.0.0", port=8000)
              EOF

              # Start the service
              python materialized_updater.py
          env:
            - name: MYSQL_HOST
              valueFrom:
                configMapKeyRef:
                  key: MYSQL_HOST
                  name: centralized-db-config
            - name: MYSQL_PORT
              valueFrom:
                configMapKeyRef:
                  key: MYSQL_PORT
                  name: centralized-db-config
            - name: MYSQL_USER
              valueFrom:
                secretKeyRef:
                  key: mysql-user
                  name: centralized-db-secrets
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: mysql-password
                  name: centralized-db-secrets
            - name: MYSQL_DATABASE
              valueFrom:
                configMapKeyRef:
                  key: MYSQL_DATABASE
                  name: centralized-db-config
          ports:
            - containerPort: 8000
              name: http
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 256Mi
      nodeSelector:
        node-type: data-collection
      tolerations:
        - effect: NoSchedule
          key: data-platform
          operator: Equal
          value: "true"
