apiVersion: apps/v1
kind: Deployment
metadata:
  name: performance-monitor
  namespace: crypto-data-collection
  labels:
    app: performance-monitor
    component: monitoring
    node-type: analytics
spec:
  replicas: 1
  selector:
    matchLabels:
      app: performance-monitor
  template:
    metadata:
      labels:
        app: performance-monitor
        component: monitoring
        node-type: analytics
      annotations:
        prometheus.io/scrape: "true"
        prometheus.io/port: "8000"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: performance-monitoring
      nodeSelector:
        node-type: analytics
      tolerations:
        - key: "analytics-infrastructure"
          operator: "Equal"
          value: "true"
          effect: "NoSchedule"
      containers:
        - name: performance-monitor
          image: python:3.11-slim
          ports:
            - containerPort: 8000
              name: http
          command:
            - /bin/bash
            - -c
          args:
            - |
              # Install dependencies
              pip install fastapi uvicorn prometheus-client psutil mysql-connector-python redis kubernetes

              # Create application directory
              mkdir -p /app

              # Create the performance monitoring service
              cat > /app/main.py << 'EOF'
              import asyncio
              import logging
              import os
              import time
              import psutil
              from datetime import datetime, timedelta
              from contextlib import contextmanager
              import mysql.connector
              import redis
              from fastapi import FastAPI
              from prometheus_client import Counter, Histogram, Gauge, generate_latest, start_http_server
              import uvicorn
              from kubernetes import client, config

              # Configure logging
              logging.basicConfig(level=logging.INFO)
              logger = logging.getLogger(__name__)

              # Prometheus metrics
              RESOURCE_CPU_USAGE = Gauge('resource_cpu_usage_percent', 'CPU usage percentage', ['pod', 'namespace', 'node'])
              RESOURCE_MEMORY_USAGE = Gauge('resource_memory_usage_bytes', 'Memory usage in bytes', ['pod', 'namespace', 'node'])
              RESOURCE_MEMORY_PERCENT = Gauge('resource_memory_usage_percent', 'Memory usage percentage', ['pod', 'namespace', 'node'])
              RESOURCE_DISK_USAGE = Gauge('resource_disk_usage_percent', 'Disk usage percentage', ['pod', 'namespace', 'node'])
              RESOURCE_NETWORK_BYTES = Gauge('resource_network_bytes_total', 'Network bytes transferred', ['pod', 'namespace', 'node', 'direction'])

              DATABASE_CONNECTIONS = Gauge('database_connections_active', 'Active database connections', ['database'])
              DATABASE_QUERY_DURATION = Histogram('database_query_duration_seconds', 'Database query duration', ['database', 'query_type'])
              DATABASE_QUERY_COUNT = Counter('database_queries_total', 'Total database queries', ['database', 'query_type', 'status'])

              REDIS_CONNECTIONS = Gauge('redis_connections_active', 'Active Redis connections', ['redis_instance'])
              REDIS_MEMORY_USAGE = Gauge('redis_memory_usage_bytes', 'Redis memory usage', ['redis_instance'])
              REDIS_KEY_COUNT = Gauge('redis_keys_total', 'Total Redis keys', ['redis_instance'])

              SERVICE_RESPONSE_TIME = Histogram('service_response_time_seconds', 'Service response time', ['service', 'endpoint'])
              SERVICE_ERROR_RATE = Counter('service_errors_total', 'Service errors', ['service', 'error_type'])
              SERVICE_THROUGHPUT = Counter('service_requests_total', 'Service requests', ['service', 'endpoint'])

              COST_ESTIMATION = Gauge('cost_estimation_usd_per_hour', 'Estimated cost per hour', ['resource_type', 'node'])
              PERFORMANCE_SCORE = Gauge('performance_score', 'Overall performance score (0-100)')

              @contextmanager
              def get_connection_context():
                  """Database connection context manager"""
                  conn = None
                  try:
                      conn = mysql.connector.connect(
                          host=os.getenv('MYSQL_HOST', 'host.docker.internal'),
                          port=int(os.getenv('MYSQL_PORT', 3306)),
                          user=os.getenv('MYSQL_USER', 'news_collector'),
                          password=os.getenv('MYSQL_PASSWORD', '99Rules!'),
                          database=os.getenv('MYSQL_DATABASE', 'crypto_prices')
                      )
                      yield conn
                  except Exception as e:
                      logger.error(f"Database connection error: {e}")
                      if conn:
                          conn.rollback()
                      raise
                  finally:
                      if conn:
                          conn.close()

              class PerformanceMonitor:
                  def __init__(self):
                      self.app = FastAPI(title="Performance Monitor Service", version="1.0.0")
                      self.setup_routes()
                      
                      # Kubernetes client
                      try:
                          config.load_incluster_config()
                          self.k8s_client = client.CoreV1Api()
                          self.k8s_apps_client = client.AppsV1Api()
                      except:
                          logger.warning("Could not load Kubernetes config, running in external mode")
                          self.k8s_client = None
                          self.k8s_apps_client = None
                      
                      # Redis client
                      try:
                          self.redis_client = redis.Redis(
                              host=os.getenv('REDIS_HOST', 'redis-data-collection.crypto-data-collection.svc.cluster.local'),
                              port=int(os.getenv('REDIS_PORT', 6379)),
                              decode_responses=True
                          )
                          self.redis_client.ping()
                      except Exception as e:
                          logger.error(f"Redis connection error: {e}")
                          self.redis_client = None
                      
                      logger.info("ðŸš€ Performance Monitor initialized")

                  def setup_routes(self):
                      @self.app.get("/health")
                      async def health():
                          return {
                              "status": "healthy",
                              "service": "performance-monitor",
                              "version": "1.0.0",
                              "k8s_client": self.k8s_client is not None,
                              "redis_client": self.redis_client is not None
                          }

                      @self.app.get("/metrics")
                      async def metrics():
                          return generate_latest()

                      @self.app.get("/performance")
                      async def performance_summary():
                          return await self.get_performance_summary()

                  async def get_pod_metrics(self):
                      """Get resource metrics for all pods in namespace"""
                      if not self.k8s_client:
                          return {}
                      
                      try:
                          pods = self.k8s_client.list_namespaced_pod(
                              namespace="crypto-data-collection"
                          )
                          
                          pod_metrics = {}
                          for pod in pods.items:
                              if pod.status.phase == "Running":
                                  pod_name = pod.metadata.name
                                  node_name = pod.spec.node_name
                                  
                                  # Get container resource usage
                                  for container in pod.status.container_statuses:
                                      if container.name and container.state.running:
                                          # Note: In a real implementation, you'd use metrics-server or cAdvisor
                                          # For now, we'll simulate metrics
                                          pod_metrics[pod_name] = {
                                              'node': node_name,
                                              'cpu_percent': 0.0,  # Would get from metrics-server
                                              'memory_bytes': 0,   # Would get from metrics-server
                                              'memory_percent': 0.0
                                          }
                          
                          return pod_metrics
                      except Exception as e:
                          logger.error(f"Error getting pod metrics: {e}")
                          return {}

                  async def get_database_metrics(self):
                      """Get database performance metrics"""
                      try:
                          with get_connection_context() as conn:
                              cursor = conn.cursor()
                              
                              # Get connection count
                              cursor.execute("SHOW STATUS LIKE 'Threads_connected'")
                              connections = cursor.fetchone()[1]
                              
                              # Get query count
                              cursor.execute("SHOW STATUS LIKE 'Queries'")
                              queries = cursor.fetchone()[1]
                              
                              # Get database size
                              cursor.execute("""
                                  SELECT
                                      ROUND(SUM(data_length + index_length) / 1024 / 1024, 2) AS 'DB Size in MB'
                                  FROM information_schema.tables
                                  WHERE table_schema = %s
                              """, (os.getenv("MYSQL_DATABASE", "crypto_prices"),))
                              db_size = cursor.fetchone()[0]
                              
                              cursor.close()
                              
                              return {
                                  'connections': int(connections),
                                  'queries': int(queries),
                                  'size_mb': db_size
                              }
                      except Exception as e:
                          logger.error(f"Error getting database metrics: {e}")
                          return {}

                  async def get_redis_metrics(self):
                      """Get Redis performance metrics"""
                      if not self.redis_client:
                          return {}
                      
                      try:
                          info = self.redis_client.info()
                          return {
                              'connected_clients': info.get('connected_clients', 0),
                              'used_memory': info.get('used_memory', 0),
                              'keyspace_hits': info.get('keyspace_hits', 0),
                              'keyspace_misses': info.get('keyspace_misses', 0),
                              'total_commands_processed': info.get('total_commands_processed', 0)
                          }
                      except Exception as e:
                          logger.error(f"Error getting Redis metrics: {e}")
                          return {}

                  async def get_service_metrics(self):
                      """Get service performance metrics"""
                      services = [
                          'enhanced-crypto-prices',
                          'crypto-news-collector',
                          'sentiment-collector',
                          'materialized-updater',
                          'data-collection-health-monitor'
                      ]
                      
                      service_metrics = {}
                      for service in services:
                          try:
                              # In a real implementation, you'd call each service's metrics endpoint
                              # For now, we'll simulate
                              service_metrics[service] = {
                                  'response_time': 0.1,
                                  'error_rate': 0.0,
                                  'throughput': 100
                              }
                          except Exception as e:
                              logger.error(f"Error getting metrics for {service}: {e}")
                      
                      return service_metrics

                  async def calculate_performance_score(self, pod_metrics, db_metrics, redis_metrics, service_metrics):
                      """Calculate overall performance score (0-100)"""
                      score = 100
                      
                      # Deduct points for high resource usage
                      for pod_name, metrics in pod_metrics.items():
                          if metrics['cpu_percent'] > 80:
                              score -= 10
                          if metrics['memory_percent'] > 80:
                              score -= 10
                      
                      # Deduct points for database issues
                      if db_metrics.get('connections', 0) > 50:
                          score -= 5
                      if db_metrics.get('size_mb', 0) > 10000:  # 10GB
                          score -= 5
                      
                      # Deduct points for Redis issues
                      if redis_metrics.get('connected_clients', 0) > 100:
                          score -= 5
                      
                      # Deduct points for service issues
                      for service, metrics in service_metrics.items():
                          if metrics['error_rate'] > 0.05:  # 5% error rate
                              score -= 10
                          if metrics['response_time'] > 1.0:  # 1 second
                              score -= 5
                      
                      return max(0, score)

                  async def update_metrics(self):
                      """Update all Prometheus metrics"""
                      try:
                          # Get metrics from all sources
                          pod_metrics = await self.get_pod_metrics()
                          db_metrics = await self.get_database_metrics()
                          redis_metrics = await self.get_redis_metrics()
                          service_metrics = await self.get_service_metrics()
                          
                          # Update Prometheus metrics
                          for pod_name, metrics in pod_metrics.items():
                              RESOURCE_CPU_USAGE.labels(
                                  pod=pod_name, 
                                  namespace="crypto-data-collection",
                                  node=metrics['node']
                              ).set(metrics['cpu_percent'])
                              
                              RESOURCE_MEMORY_USAGE.labels(
                                  pod=pod_name,
                                  namespace="crypto-data-collection", 
                                  node=metrics['node']
                              ).set(metrics['memory_bytes'])
                              
                              RESOURCE_MEMORY_PERCENT.labels(
                                  pod=pod_name,
                                  namespace="crypto-data-collection",
                                  node=metrics['node']
                              ).set(metrics['memory_percent'])
                          
                          # Database metrics
                          if db_metrics:
                              DATABASE_CONNECTIONS.labels(database="mysql").set(db_metrics.get('connections', 0))
                          
                          # Redis metrics
                          if redis_metrics:
                              REDIS_CONNECTIONS.labels(redis_instance="main").set(redis_metrics.get('connected_clients', 0))
                              REDIS_MEMORY_USAGE.labels(redis_instance="main").set(redis_metrics.get('used_memory', 0))
                          
                          # Service metrics
                          for service, metrics in service_metrics.items():
                              SERVICE_RESPONSE_TIME.labels(service=service, endpoint="health").observe(metrics['response_time'])
                              SERVICE_ERROR_RATE.labels(service=service, error_type="http").inc(metrics['error_rate'])
                              SERVICE_THROUGHPUT.labels(service=service, endpoint="health").inc(metrics['throughput'])
                          
                          # Calculate and set performance score
                          performance_score = await self.calculate_performance_score(
                              pod_metrics, db_metrics, redis_metrics, service_metrics
                          )
                          PERFORMANCE_SCORE.set(performance_score)
                          
                          logger.info(f"Updated performance metrics, score: {performance_score}/100")
                          
                      except Exception as e:
                          logger.error(f"Error updating metrics: {e}")

                  async def get_performance_summary(self):
                      """Get comprehensive performance summary"""
                      pod_metrics = await self.get_pod_metrics()
                      db_metrics = await self.get_database_metrics()
                      redis_metrics = await self.get_redis_metrics()
                      service_metrics = await self.get_service_metrics()
                      
                      performance_score = await self.calculate_performance_score(
                          pod_metrics, db_metrics, redis_metrics, service_metrics
                      )
                      
                      return {
                          "performance_score": performance_score,
                          "pod_count": len(pod_metrics),
                          "database_connections": db_metrics.get('connections', 0),
                          "database_size_mb": db_metrics.get('size_mb', 0),
                          "redis_connections": redis_metrics.get('connected_clients', 0),
                          "redis_memory_bytes": redis_metrics.get('used_memory', 0),
                          "service_count": len(service_metrics),
                          "timestamp": datetime.now().isoformat()
                      }

                  async def start_monitoring_loop(self):
                      """Start continuous monitoring loop"""
                      logger.info("Starting performance monitoring loop")
                      
                      while True:
                          try:
                              await self.update_metrics()
                              await asyncio.sleep(30)  # Update every 30 seconds
                          except Exception as e:
                              logger.error(f"Error in monitoring loop: {e}")
                              await asyncio.sleep(60)  # Wait longer on error

              # Create monitor instance
              monitor = PerformanceMonitor()
              app = monitor.app

              if __name__ == "__main__":
                  logger.info("ðŸš€ Starting Performance Monitor Service")
                  
                  # Start background monitoring
                  import threading
                  def start_monitoring():
                      loop = asyncio.new_event_loop()
                      asyncio.set_event_loop(loop)
                      loop.run_until_complete(monitor.start_monitoring_loop())
                  
                  monitoring_thread = threading.Thread(target=start_monitoring, daemon=True)
                  monitoring_thread.start()
                  
                  # Start the service
                  uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
              EOF

              # Start the service
              cd /app && python main.py
          env:
            - name: MYSQL_HOST
              valueFrom:
                configMapKeyRef:
                  name: centralized-db-config
                  key: MYSQL_HOST
            - name: MYSQL_PORT
              valueFrom:
                configMapKeyRef:
                  name: centralized-db-config
                  key: MYSQL_PORT
            - name: MYSQL_USER
              valueFrom:
                secretKeyRef:
                  name: centralized-db-secrets
                  key: mysql-user
            - name: MYSQL_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: centralized-db-secrets
                  key: mysql-password
            - name: MYSQL_DATABASE
              valueFrom:
                configMapKeyRef:
                  name: centralized-db-config
                  key: MYSQL_DATABASE
            - name: REDIS_HOST
              valueFrom:
                configMapKeyRef:
                  name: centralized-db-config
                  key: REDIS_HOST
            - name: REDIS_PORT
              valueFrom:
                configMapKeyRef:
                  name: centralized-db-config
                  key: REDIS_PORT
          resources:
            requests:
              cpu: 100m
              memory: 256Mi
            limits:
              cpu: 500m
              memory: 512Mi
          livenessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 30
            periodSeconds: 30
          readinessProbe:
            httpGet:
              path: /health
              port: 8000
            initialDelaySeconds: 10
            periodSeconds: 10
---
apiVersion: v1
kind: Service
metadata:
  name: performance-monitor
  namespace: crypto-data-collection
  labels:
    app: performance-monitor
    component: monitoring
spec:
  ports:
    - port: 8000
      targetPort: 8000
      protocol: TCP
      name: http
  selector:
    app: performance-monitor
  type: ClusterIP
